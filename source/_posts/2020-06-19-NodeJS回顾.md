---
title: NodeJs回顾
date: 2020-06-19  16:46:38
tags: NodeJs
categories: 
	- NodeJs
---




# NodeJS

## 模块与文件

### require 的加载机制

#### 模块的分类

系统模块

- C/C++模块，也叫build-in内建模块，一般用于native模块嗲用，在require出去
- native模块，在开发中使用的Node.js 的 http/buffer/fs等，底层也是调用的内建模块（C/C++）

第三方模块：

非Node.js自带的模块被称为第三方模块，会分成路径形式的文件模块（以`.`、`..`、`/`开头的）和自定义的模块（比如express/koa/moment.js等）

在 Node.JS 中模块加载一般会经历3个步骤：路径分析、文件定位、编译执行

按照模块的分类，按照以下的顺序进行优先加载：

- 系统缓存：模块被执行之后会进行缓存，首先是先进行缓存加载，判断换粗中是否有值。
- 系统模块：也就是原生模块，优先级次于系统缓存，部分核心模块已经被编译成二进制，省略了路径分析、文件定位，直接加载在内存中，系统模块定义在 Node.js 源码的lib目录下。
- 文件模块：优先加载 `.`、`..`、`/`开头的，如果文件没有加上拓展名，会依次按照`.js`、`.json`、`.node`尝试进行拓展名补足。（在尝试过程中也是以**同步阻塞模式**来判断文件是否存在的，从性能优化角度来看，`.json`、`node`最好还是加上文件的拓展名）
- 目录作为模块：文件模块加载过程中没有找到，但发现这是一个目录，这个适合就会把这个目录当做一个包来处理，Node采用了commonjs规范，会先在项目的根目录查找package.json文件，取出文件中定义的main属性描述的入口文件进行加载，也没有加载到，则会抛出默认错误：Error：Cannot find module 'lib/hello.js'
- node_modules目录加载：对于系统模块，路径文件模块都找不到，Nodejs会从当前模块的父目录进行查找，直到系统的根目录

### module.exports 与 exports 的区别

exports相当于 module.exports 的快捷方式：

```js
const exports = module.exports 
```

但是不能改变 exports 的指向，我们可以通过 `exports.test = 'a'`，这样来导出一个对象，但是不能通过下面的例子直接赋值，这样会改变 exports 的指向

```js
// 错误的写法，将会得到 undefined
exports = {
   'a':1,
   'b':2 
}

// 正确的写法
modules.exports ={
   'a':1,
   'b':2 
}
```



### 模块循环引用问题

```js
// a.js
console.log('a模块start');
exports.test = 1;
undeclaredVariable = 'a模块为声明变量'
const b = require('./b');
console.log('a模块加载完毕：b.test值',b.test);

// b.js 
console.log('b模块start');
exports.test = 2;
const a = require('./a');
console.log('undeclaredVariable:',undeclaredVariable)
console.log('b模块加载完毕：a.test值：',a.test)
```

执行 `node a.js`,结果：

```shell
a模块start
b模块start
undeclaredVariable:a模块未声明变量
b模块加载完毕：a.test值：1
a模块加载完毕：b.test值：2
```

启动a.js会加载b.js，那么在b.js中又加载到了a.js，但是此时a.js模块hi阿咩有执行完，返回的是一个a.js模块的exports对象未完成的副本给到b.js模块（因此不会陷入死循环），然后b.js完成加载之后将exports 对象退供给a.js模块

#### a 模块中的 undeclaredVariable 变量在 b.js 是否会打印？

undeclaredVariable 是一个未声明的变量，也就是一个挂在全局的变量，那么在其他地方是可以拿得到的

#### 假设有 a.js、b.js 两个模块相互引用，会有什么问题，会不会陷入死循环？

不会陷入死循环

## Buffer

### Buffer与Cache的区别

#### 缓冲（Buffer）

缓冲是用于处理二进制流数据，将数据存储起来，它是临时性的，对于流式数据来说，会采用缓冲区将数据临时存储起来，等缓冲到一定大小的时候存入硬盘中。视频播放器就是一个经典例子。

#### 缓存（Cache）

缓存可以看做一个中间层，可以是永久性的将热点数据进行缓存，使得访问速度更快。例如我们通过对 memory、Redis等将数据从硬盘或者第三方接口中请求过来进行缓存，目的就是将数据存于内存的缓存区中，这样对同一个资源进行访问，速度会更快，也就是性能优化的一个重要点。



## 线程与进程

#### 什么是进程（Process）和线程（Thread），之间的区别

##### 进程

进程是计算中程序关于数据集合上的一次运行活动，是系统进行资源分配和调度的基本单位，是操作系统结构的基础，进程是线程的容器。启动一个服务，运行一个实例，就是开一个服务进程。多进程就是进程的复制（fork），fork出来的每个进程都有自己的独立空间地址、数据栈，一个进程无法访问另外一个进程里定义的变量、数据结构，只有建立了IPC通信，进程之间才可以数据共享。

##### 线程

线程是操作系统能够进行运算调度的最小单位，线程是隶属进程的，被包含与进程之中的。一个线程只能隶属一个进程，但是一个进程是可以拥有多个线程的。



同一个代码，可以根据系统CPU核心数启动多个进程，每个进程都有属于自己的独立运行空间，进程之间是不互相影响的。同一进程中的多条线程将共享该进程中的全部系统资源，如虚拟地址空间，文件描述和信号处理等。但 同一进程中的多个线程有各自的调用栈，自己的寄存器环境，自己的线程本地存储。



### 什么是孤儿进程

父进程创建子进程之后，父进程退出了，但是父进程对应的一个或者多个子进程还在运行，这些子进程会被系统的init进程收养，对应的程序ppid为1，这就是孤儿进程。



### 创建多进程时，代码里有`app.listen(port)`在进行fork时，为什么没有报端口被占用

端口被占用的情况：

```js
// master.js
const fork = require('child_process').fork;
const cups = require('os').cups();

for(let i=0;i<cups.length;i++){
    const worker = fork('worker.js')
    console.log('worker process created, pid: %s ppid: %s', worker.pid, process.pid);
}

// worker.js
const http = require('http');
http.createServer((req,res)=>{
    res.send('I am worker,pid:'+process.pid+', ppid: '+process.pid)
}).listen(3000);

// 控制台执行node master.js只有一个worker 可以监听 3000 端口，其余会抛出 Error:listen EADDRINUSE :::3000错误
```

多进程模式可通过句柄传递不会有端口占用的问题。

当父子进程之间建立IPC通道之后，通过子进程对象的send方法发送消息，第二个参数sendHandle就是句柄，可以是TCP套接字，TCP服务器、UDP套接字等，为了解决上面多进程端口占用问题，将主进程的socket传递到子进程：

```js
// master.js
const fork = require('child_process').fork;
const cups = require('os').cpus();
const server = require('net').createServer();
server.listen(3000);
process.title = 'node-master';

for(let i=0;i<cpus.length;i++){
    const worker = fork('worker.js')
    worker.send('server',server);
    console.log('worker process created, pid: %s ppid: %s', worker.pid, process.pid);
    
    if(i+1 === cpus.length){
        console.log('serve close');
        server.close(); // 关闭服务器监听，交由子进程处理
    }
}

// worker.js
const http = require('http');
const server = http.createServer((req,res)=>{
    res.end('I am worker, pid: ' + process.pid + ', ppid: ' + process.ppid);
})
let worker;
process.title = 'node-worker';
process.on('message',(message,sendHandle)=>{
    if(message === 'server'){
        worker = sendHandle;
        worker.on('connection',(socket)=>{
            server.emit('connection',socket)
        })
    }
})
```



### 什么是IPC通信，如何建立，什么场景下会使用

IPC(inter-process communication)，即进程间通信技术，由于每个进程创建之后都有自己的独立地址空间，实现IPC的目的就是进程之间的资源共享访问，实现IPC的方式有多种：管道、消息队列、信号量、Domain Socket，Nodejs通过pipe来实现。

未使用IPC的情况：

```javascript
// pipe.js
const spawn = require('child_process').spawn;
const child = spawn('node',['worker.js']);
console.log(process.pid,child.pid);

// worker.js
console.log('I am worker,PID:',process.pid)

// 执行 node pipe.js，输出主线程的id，子线程的id，但是子线程worker.js的信息没有在控制台打印，原因是新创建的子进程有自己的 stdio流
```

创建一个父进程和子进程之间传递消息的IPC通道实现输出信息

```javascript
// 修改pipe.js让子进程的stdio和当前进程的stdio之间建立管道链接，还可以通过spawn方法的stdio选项建立IPC机制
// pipe.js
const spawn = require('child_process').spawn;
const child = spawn('node',['worker.js']);
child.stdout.pipe(process.stdout);
console.log(process.pid,child.pid);

// 父进程与子进程的通信
// 父进程在创建子进程之前会先去创建IPC通道并一直监听该通道，之后开始创建子进程并通过环境变量（NODE_CHANNEL_FD）的方式将IPC频道的文件描述符传递给子进程，子进程启动时根据传递的文件描述符去链接IPC通道，从而建立父子进程之间的通信机制。
```



### Node.js是单线程还是多线程，为什么会单线程

javascript是单线程，在服务端运行环境的nodejs不是单线程。

浏览器环境中对于DOM的操作是单线程的，避免DOM渲染冲突，在浏览器中UI渲染线程和JS执行引擎是互斥的，一方在执行式都会导致另一方被挂起，这是由JS引擎所决定的。

### 关于守护进程，是什么，为什么，怎么编写？

守护进程运行在后台不受终端影响。

#### 创建步骤

1. 创建子进程
2. 在子进程中创建新会话（调用系统函数setsid）
3. 改变子进程工作目录（如：’/‘或者’/usr/‘等）
4. 父进程终止

### 编写demo

```javascript
// index.js文件的处理逻辑使用 spawn创建子进程完成第一步，设置options.detached为true可以使得子进程在父进程退出后继续运行（系统层会调用setsid方法），这是第二步。options.cwd指定当前子进程工作目录不做设置默认继承当前工作目录，这是第三步。运行daemon.unref()退出父进程，第四步。
// index.js
const spawn = require('child_process').spawn;

function startDaemon(){
    const daemon = spawn('node',['daemon.js'],{
        cwd:'/usr',
        datached:true,
        stdio:'ignore',
    })
    console.log('守护进程开启 父进程 pid: %s, 守护进程 pid: %s', process.pid, daemon.pid);
    daemon.unref();
}
startDaemon();

// daemon.js文件哩逻辑开启一个定时器每10秒运行一次，使得这个资源不会退出，同时写入日志到子进程当前的工作目录下
// /usr/daemon.js
const fs = require('fs');
const {Console} = require('console');

const logger = new Console(fs.createWriteStream('./stdout.log'),fs.createWriteStream('./stderr.log'));

setInterval(function(){
    logger.log('daemon pid:',process.pid,'ppid: ',process.ppid)
},1000*10)
```

实际工作中守护进程很多，例如PM2,Egg-Cluster等，实际工作上对于守护进程的健壮性要求还是很高的，例如：进程的异常监听，工作进程管理调度，进程挂掉之后重启等等。

### 实现一个简单的命令行交互程序

采用子进程 child_process的spawn方法：

```javascript
const spawn = require('child_process').spawn;
const child = spawn('echo',['简单的命令行交互']);
child.stdout.pipe(process.stdout) // 将子进程的输出作为当前进程的输入，打印在控制台
```



### 进程的当前工作目录是什么，有什么用

进程的当前工作目录可以通过process.cwd()命令获取，默认为当前启动的目录，如果是创建子进程则继承于父进程的目录，可以通过process.chdir()命令重置，例如通过spawn命令创建的子进程可以指定cwd选项设置子进程的工作目录。

有什么用，例如fs读取文件，如果设置为相对路径则是相当于当前进程启动的目录进行查找，所以，启动目的设置有误的情况下将无法得到正确的结果。还有一种情况程序里引用第三方模块也是根据当前进程启动的目录来进行查找的

### 多进程或者多个Web服务之间的状态共享问题

多进程模式下各个进程之间是相互独立的，例如用户登录之后seesion的保存，如果保存在服务进程里，那么如果我有4个工作进程，每个进程都要保存一份这是没有必要的。假设服务重启了数据也会丢失。多个Web服务也是一样的，还会出现在A机器创建了Session，当负载均衡分到B机器上之后还需要再创建一份，一般的做法是通过Redis或者数据库来做数据共享

### 什么是僵尸进程

使用fork可以创建子进程，正常情况进程退出，内核要释放进程所占用的资源：打开的文件、占用的内存等，但是进程的PID、退出状态、运行时间等会进行保留，知道父进程调用wait/waitpid来获取子进程的状态信息时，这些资源才会释放。

如果子进程退出之后，父进程没有调用wait/waitpid来获取子进程的状态，那么保留的进程号将会一直被占用，且占用系统资源，称为僵死或僵尸进程。

元凶是其父进程，我们把元凶kill掉之后，僵尸进程会变为孤儿进程被系统的 init 进程pid=1的进程所收养，init进程会对这些孤儿进程进行管理（调用wait/waitpid）释放其占用资源。

## Console

### console是异步还是同步的

console既不是总是同步的，也不总是异步的，是否为同步取决于链接是什么流以及操作系统是Window还是Posix

同步写将会阻塞实践循环直到写完成。

- 文件（Files）：Windows和POSIX平台都是同步
- 终端（TTYS）：Windows平台下同步，在POSIX平台下异步
- 管道（Pipes）：Windows平台下同步，POSIX平台下异步

### 如何实现一个console.log

可利用 process.stdout将输入流数据输出到输出流（即输出到终端）

```javascript
process.stdout.write('xxx'+'\n')
```

### 为什么console.log()执行完就退出

一旦产生事件循环，就会长产生一个While(true)的死循环，例如定时器，console.log则没有产生watch/handlers，在事件循环一次就退出了。

Nodejs进程退出会等待异步处理完成，常见的运维过程中会碰到需要进程优雅退出的场景，Nodejs自然退出是最好的，process.exit是比较粗暴的。

常见的异步请求：

- http请求，数据库请求等IO请求操作
- net.Server.listen()或者http.Server.listen等端口监听
- fs.write()类型的文件IO操作
- console.log()输出日志
- setTimeout()/setInterval等定时器操作
- process.send()等异步请求发送

## Net模块

| OSI七层模型 | TCP/IP五层模型 | 描述                                                         |
| ----------- | -------------- | ------------------------------------------------------------ |
| 应用层      | 应             | 构建于传输层之上常用的HTTP、FTP文件传输协议、SMTP邮件传输协议等 |
| 表示层      | 用             | 构建于传输层之上常用的HTTP、FTP文件传输协议、SMTP邮件传输协议等 |
| 会话层      | 层             | 构建于传输层之上常用的HTTP、FTP文件传输协议、SMTP邮件传输协议等 |
| 传输层      | 传输层         | 向用户提供可靠的端到端服务TCP、UDP                           |
| 网络层      | 网络层         | IPV4、IPV6                                                   |
| 数据链路层  | 数据链路层     | 设备驱动和硬件                                               |
| 物理层      | 物理层         | 设备驱动和硬件                                               |



### 什么是TCP协议，什么时候会选择TCP协议

IP协议是无连接通信协议，IP协议不会占用两个设备之间通信的线路，IP实际上主要负责将每个数据包路由至目的地，但是IP协议没有能确保数据包是否到达，传过去的数据是否按照顺序排列，所以IP数据包是不可靠的。而解决数据不可靠的问题就是由TCP协议来完成。

TCP（Transmission Control Protocol）是可靠的传输控制协议，三个特点：

- 面向链接：需要对方主机在线，并建立链接
- 面向字节流：发送多少字节自己说了算，每次选出一段字节发送的时候，都会带上一个序号，这个序号就是发送的这段字节中编号最小的字节的编号。
- 可靠：保证数据有序的到达对方主机，每发送一个数据就会期待收到对方的回复，在指定时间内收到了ACK回复，就确认数据到达，如果超过一定的时间没有收到对方的回复，就认为对方没有收到，再重新发送一次。

TCP报文

| 源端口（16）                                                 | 目的端口（16）   |
| ------------------------------------------------------------ | ---------------- |
| TCP序号（32）                                                | TCP序号（32）    |
| 捎带的确认（32）                                             | 捎带的确认（32） |
| 首部长度（4）保留（6）Flag（6：URG、ACK、PSH、RST、SYN、FIN） | 窗口尺寸（16）   |
| TCP校验和（16）                                              | 紧急指针（16）   |
| 数据包内容                                                   | 数据包内容       |

6个标志位：

- URG,紧急指针标志，当为1时表示紧急指针有效，为0时则忽略紧急指针
- ACK,确认序号标志，为1表示确认有效，为0表示报文不含有确认信息，确认号无误
- PSH,push标志，当为1时就是让接收方收到该TCP报文的时候不进入缓冲区排队而是快速发送给应用程序
- RST,重置连接标志，当连接出现错误的时可以重置，或者用于拒绝非法的报文段和连接请求
- SYN,同步序号，用于建立连接过程
- FIN,finish标志，用于释放连接

3次握手协议：

1. 第一次握手，当客户端需要去建立连接时，客户端就会发送SYN包（seq=x）到服务器，然后客户端进入SYN_SEND的状态，代表已经发SYN包过去，并且在等待服务器确认。此时，ACK=0,SYN=1。
2. 第二次握手，服务器收到SYN包，会进行确认，由上面的标志知道SYN是表示同步序号，这时候会使得 确认号=序号+1，即ack等于x+1,然后服务器也会像客户端发送一个SYN包（seq=y),也就是服务器会发送SYN+ACK包，来表示确认到了客户端的一次握手并且二次握手建立，此时服务器进入SYN_RECV状态。此时，ACK=1,SYN=1。
3. 第三次握手，客户端收到服务器的SYN+ACK包，然后就会向服务器发送确认包ACK(ack=y+1)和SYN(seq=x+1),等到这个包发送完毕之后客户端和服务器就会进入ESTABLISHED状态，完成三次握手，就可以在服务器与客户端之间传输数据了。

SYN是同步序号，当SYN=1而ACK=0时表明这是一个连接请求报文，对方若同意连接，那应在报文中使SYN=1和ACK=1，因此SYN置1表示这是一个连接请求或者连接接受报文。而ACK状态是用来确认是否同意连接。也就是传了SYN,证明发送方到接收方的通道没有问题，但是接收方到发送方的通道还需要ACK信号来验证

当在传送完数据之后，客户端与服务器端之间有四次握手协议：

1. 第一次握手：客户端发送一个FIN和序号过去（seq=u）用来表示客户端和服务端之间有关闭的请求，同时关闭客户端的数据传送，客户端就进入FIN_WAIT_1的状态
2. 第二次握手：服务端收到FIN=1的标志位，就会发送一个ACK标志位表示确认，然后确认序号就变成了收到的序号+1,即ack=u+1(FIN和SYN在这点相同，但是作用不一样)这时候服务端进入CLOSE_WAIT状态，这是一个半关闭状态。只能服务端给客户端发送数据而客户端不能给服务端发送数据
3. 第三次握手：这次握手还是服务端发起的。这是服务端在传完最后的数据（没有就不传）就会发送一个FIN=1和ACK=1,且序号seq会改变（没有传数据则不变），而ack不变，这时候服务端就会进入LAST_ACK状态，表示最后再确认一次。
4. 第四次握手：客户端在接收到FIN之后，就会进入TIME_WAIT状态，接着发送一个ACK和seq=u+1,ack=w+1给服务端，这时候服务端就会进入CLOSED状态。而客户端进入TIME_WAIT状态的时候必须要等待2MSL的时间才会关闭

TIME_WAIT状态的作用？（MSL：网络中数据报文存在的最大时间）

1. TIME_WAIT状态可以确保有足够的时间让对方接收到ACK包，如果ACK没有到达，在传输过程丢失了或者一些其他原因，这样就可以让客户端重发ACK包，如果客户端直接关闭了，那么就有可能导致服务端在一些情况下没有接受到ACK包而无法与客户端断开连接。这样客户端发送ACK包到服务端，服务端请求重发，一来一回就刚好是2MSL
2. 保证迟来的TCP报文段有足够的时间被识别并丢弃，linux中一个TCPort不能打开两次或者两次以上。当client处于time_wait状态时无法使用此port建立新连接，假设不存在time_wait状态，新连接可能会受到旧连接的数据

### TCP粘包是什么,该怎么办

客户端（发送一端）在发送之前会将短时间有多个发送的数据块缓冲到一起（发送缓冲区），形成了一个大的数据块一并发送，同样接收端也有一个接收缓冲区，收到的数据先存放在接收端缓冲区，然后程序从这里读取部分数据进行消费，这样做也是为了减少I/O消耗达到性能优化。

数据达到缓冲区什么时间开发发送这个取决于TCP拥塞控制，是任何时刻内确定能被发送出去的字节数的控制因素之一，是阻止发送方至接收方之间的链路变得拥塞的手段

TCP粘包解决方案：

1. 延迟发送：设置延迟发送，sleep休眠一段时间。简单但是传输效率大大降低，只适用于交互频率低的情况

2. 关闭nagle算法。nagle算法是一种改善网络传输效率的算法，避免网络中充斥着大量小的数据块，它所期望的是尽可能发送大的数据块，因此在每次请求一个数据块给TCP发送时，TCP并不会立即执行发送，而是等待一小段时间进行发送。

   当网络中充斥着大量小的数据块时，Nagle算法能将小的数据块集合起来一起发送减少了网络拥堵，但并不是所有场景都需要这样。例如，REPL终端交互，当用户输入单个字符以获取响应，所以在nodejs中可以设置 socket.setNoDelay方法来关闭Nagle算法。`const server = net.createServer(); server.on('connection',socket=>{socket.setNoDelay(true)})`

3. 封包/拆包。使用长度编码的方式，通信双方约定好格式，将消息分为定长的消息头（Header）和不定长的消息体（Body），在解析时读取消息头获取到内容的占用的长度，之后读取到的消息体内容字节数等于字节头的字节数时，认为它是一个完整的包。

| 消息头序号（Header） | 消息体长度（Header） | 消息体（Body） |
| -------------------- | -------------------- | -------------- |
| SerialNumber         | bodyLength           | body           |
| 2字节                | 2字节                | N字节          |

Buffer的几个api：

- Buffer.alloc(size[,fill[,encoding]]),初始化一个size大小的Buffer空间，默认填充0，也可以指定fill进行自动以填充
- Buffer.writeInt16BE(value[,offset]),value为要写入的Buffer值，offset为偏移量从哪个位置开始写入
- Buffer.writeInt32BE(value[,offset]),value为要写入的Buffer值，不同的是writeInt16BE表示高位优先写入一个16位整型，这个是32位
- Buffer.readInt16BE([offset])，高位优先读取16位整型，offset为读取之前要跳过的字节数
- Buffer.readInt32BE([offset])，高位优先读取32位整型，offset为读取之前要跳过的字节数

#### 编码/解码的实现

TCP顶层是基于二进制数据，应用层通常是易于表达的字符串、数字等，需要先将数据通过Buffer转换为二进制，取出的时候同样需要解码操作。

```javascript
// transcoder.js
class Transcoder {
  constructor() {
    this.packageHeaderLen = 4; // 包头长度
    this.serialNumber = 0; // 定义包序号
    this.packageSerialNumberLen = 2; // 包序列号所占用的字节
  }
  /**
   * 编码
   * @param {Object} data Buffer 对象数据
   * @param {Int} serialNumber 包序号，客户端编码时自动生成，服务器解码之后在编码时需要传入解码的包序号
  */

  encode(data, serialNumber) {
    const body = Buffer.from(data);
    const header = Buffer.alloc(this.packageHeaderLen);
    header.writeInt16BE(serialNumber || this.serialNumber);
    header.writeInt16BE(body.length, this.packageSerialNumberLen); // 跳过包序号的前两位

    if (serialNumber === undefined) {
      this.serialNumber++;
    }
    return Buffer.concat([header, body])
  }

  /**
   * 解码
   * @param {Object} buffer
  */

  decode(buffer) {
    const header = buffer.slice(0, this.packageHeader); // 获取包头
    const body = buffer.slice(this.packageHeaderLen); // 获取包尾部

    return {
      serialNumber: header.readInt16BE(),
      bodyLength: header.readInt16BE(this.packageSerialNumberLen), // 因为编码阶段跳过两位，所以解码也需要跳过
      body: body.toString(),
    }
  }

  /**
   * 获取包长度两种情况
   * 1. 如果当前buffer长度数据小于包头，肯定不是一个完整的数据包，因此直接返回0不做处理（可能数据还没有接收完）
   * 2. 否则返回这个完整的数据包长度
   * @param {*} buffer
  */

  getPackageLength(buffer) {
    if (buffer.length < this.packageHeaderLen) {
      return 0;
    }
    return this.packageHeaderLen + buffer.readInt16BE(this.packageSerialNumberLen)
  }
}


module.exports = Transcoder;
```

客户端

```javascript
const net = require('net');
const Transcoder = require('./transcoder');

const transcoder = new Transcoder();

const client = net.createConnection({
  host: '127.0.0.1',
  port: 3000
})

let overageBuffer = null; //上一次Buffer剩下的数据


client.on('data', buffer => {
  if (overageBuffer) {
    buffer = Buffer.concat([overageBuffer, buffer])
  }

  let packageLength = 0;

  // eslint-disable-next-line no-cond-assign
  while (packageLength = transcoder.getPackageLength(buffer)) {
    const packageData = buffer.slice(0, packageLength); // 取出整个数据包
    buffer = buffer.slice(packageLength); // 删除已经取出的数据包，这里采用的方法是把缓冲区（buffer）已取出的包给截掉
    const result = transcoder.decode(packageData); // 解码
    console.log(result)
  }

  overageBuffer = buffer; // 记录剩余不完整的包
}).on('error', err => { // 监听一个未开启的端口就会报 ECONNREFUSED错误
  console.log(`服务器异常: ${err}`)
}).on('close', err => {
  console.log(`客户链接断开！， ${err}`)
})

client.write(transcoder.encode('Nodejs 技术栈'))

const arr = [
  '1 JavaScript ',
  '2 TypeScript ',
  '3 Python ',
  '4 Java ',
  '5 C ',
  '6 PHP ',
  '7 ASP.NET ',
];

setTimeout(() => {
  for (let i = 0; i < arr.length; i++) {
    console.log(arr[i])
    client.write(transcoder.encode(arr[i]))
  }
}, 1000)
```

服务端

```javascript
const net = require('net');
const Transcoder = require('./transcoder');
const transcoder = new Transcoder();
const HOST = '127.0.0.1';
const PORT = 3000;
let overageBuffer = null; // 上一次善剩余数据

// 创建一个TCP服务实例
const server = net.createServer();

// 监听端口
server.listen(PORT, HOST)

server.on('listening', () => {
  console.log(`服务已经开启在${HOST}:${PORT}`)
}).on('connection', socket => {
  // data事件就是读取数据
  socket.on('data', buffer => {
    if (overageBuffer) {
      buffer = Buffer.concat([overageBuffer, buffer])
    }
    let packageLength = 0;
    // eslint-disable-next-line no-cond-assign
    while (packageLength = transcoder.getPackageLength(buffer)) {
      const packageData = buffer.slice(0, packageLength); //取出整个数据包
      buffer = buffer.slice(packageLength); // 删除取出的数据包，这里采用的方法是把缓冲区buffer已取出的包截掉
      const result = transcoder.decode(packageData); // 解码
      console.log(result);
      socket.write(transcoder.encode(result.body, result.serialNumber))
    }
    overageBuffer = buffer; // 记录不完整的包  
  }).on('end', () => {
    console.log('socket end')
  }).on('error', error => {
    console.log('socket error', error)
  })
}).on('close', () => {
  console.log('Server Close!')
}).on('error', err => {
  if (err.code === 'EADDRINUSE') {
    console.log('地址正被使用，重试中......')

    setTimeout(() => {
      server.close();
      server.listen(PORT.HOST)
    }, 1000)
  } else {
    console.log(`服务器异常: ${err}`)
  }

})

```

## DNS

DNS模块是基于UDP协议来实现的，在Nodejs中可以通过`require('dns')`实现域名的解析查询，Nodejs DNS模块分成两大类：

1. 底层操作系统工具进行域名解析
2. 链接到一个DNS网络服务器执行域名解析

### 底层操作工具域名解析

```javascript
// Nodejs DNS模块的 dns.lookup()方法使用底层操作系统进行域名解析，是不需要经过网络通信的
const dns = require('dns');

dns.lookup('laibh.top',(err,address,family)=>{
    console.log(`地址: ${address},地址族：${family}`)
})
```

### 链接到DNS服务器执行域名解析

```javascript
// dns 模块除了 dns.lookup之外的函数，都会连接到实际DNS服务器以执行名称解析并始终使用网络执行DNS查询
const dns = require('dns');
dns.lookup('laibh.top',(err,records)=>{
    console.log(records)
})
```



`dns.lookup与dns.resolve`不同

虽然用异步的角度来使用dns.lookup，但是内部的libuv底层线程池中确实同步的调用 getaddrinfo(3)，所以可能有由于一些不确定的因素造成Node进程阻塞

与dns.lookup不同的是dns.resolve没有使用getaddrinfo(3)，而通过网络执行的DNS查询，始终保持异步不会对其他进程产生负面影响

### DNS域名解析过程

1. 浏览器DNS缓存。访问一个URL优先查找浏览器的DNS缓存，命中就返回。未命中就继续下一步，查找操作系统的缓存。当修改了本地hosts域名指向发现浏览器缓存没有变化是因为每个浏览器有一个固定值。
2. 系统（OS）缓存。查看操作系统中是否有域名对应的IP,位于操作系统的hosts文件。
3. 路由器缓存。当浏览器DNS与系统OS缓存均没有映射的时候，则请求会发送到路由器缓存中检查
4. ISP DNS缓存。ISP为互联网服务提供商。

DNS本地解析指的是系统缓存这一阶段，在浏览器缓存没有命中的情况下， 会从本地系统的一个hosts文件中寻找对应的IP

## Cluster （集群）

在PM2的配置文件中可以设置`exec_model:'cluster`和`instance`两个属性来设置开启多个进程，PM2其实就是利用Nodejs Cluster这个模块来实现的，还有eggJs中的egg-cluster模块在启用Worker进程也是用到这个模块。

```javascript
const cluster = require('cluster');
const http = require('http');
const numCPUs = require('os').cpus().length;

if (cluster.isMaster) {
  console.log(`Master 进程 ${process.pid} 正在运行`)

  for (let i = 0; i < numCPUs; i++) {
    cluster.fork();
  }

  cluster.on('exit', (worker, code, signal) => { console.log(`Worker ${worker.process.pid} 已退出`) });
} else {
  http.createServer((req, res) => {
    res.send(`你好，哈哈哈 ${process.pid}`)
  }).listen(8000);
  console.log(`Worker 进程 ${process.pid} 已启用`)
}
```

### 采用了哪种集群方式

集群模式通常实现有两种：

1. 1个Node实例开启多个端口，通过反向代理服务器向各端口服务进行转发
2. 1个Node实例开启多个进程监听同一个端口，通过负载均衡技术分配请求（Master->Worker）

第一个方案存在的一个问题就是占用多个端口，造成资源浪费，由于多个实例是独立运行的，进程间通信不太好做。好处是稳定性高，各实例之间没有影响。

第二个方案多个Node进程去监听同一个端口，好处是进程间通信相对简单，减少了端口的资源浪费，但是这个时候需要保证服务进程的稳定性，特别是对Master进程稳定性要求会更高，编码也会复杂。

Nodejs中自带的Cluster模块正是采用了第二种方案。

### 多个进程为什么可以监听同一个端口

端口不是被所有的进程全部监听，仅仅受到Master进程的监听。Master进程创建一个Socket并绑定监听到目标端口，通过子进程之间建立IPC通道之后，通过调用子进程的send方法，将Socket（链接句柄）传递过去。（Master通过cluster.fork方法创建的，本质上还是使用了child_process.fork这个方法）



使用 child_process.fork()创建的子进程，进行Socket传递的示例

```javascript
// master.js
const fork = require('child_process').fork;
const cpus = require('os').cpus();
const server = require('net').createServer().listen(3000);

for (let i=0; i<cpus.length; i++) {
    const worker = fork('worker.js');
      // 将 Master 的 server 传递给子进程
    worker.send('server', server);
    console.log('worker process created, pid: %s ppid: %s', worker.pid, process.pid);
}
// worker.js
const http = require('http');
const server = http.createServer((req, res) => {
    res.end('I am worker, pid: ' + process.pid + ', ppid: ' + process.ppid);
});

let worker;
// 第二个参数 sendHandle 就是句柄，可以是 TCP套接字、TCP服务器、UDP套接字等
process.on('message', function (message, sendHandle) {
    if (message === 'server') {
        worker = sendHandle;
        worker.on('connection', function(socket) {
            server.emit('connection', socket);
        });
    }
});
```

端口会被主进程绑定监听一次，但是主进程和子进程在建立IPC通信之后，发送Socket到子进程实现端口共享，在之后Master接受到新的客户端链接后，通过负载均衡技术再转发到各Worker进程。



### 多个进程之间如何通信

由于cluster.fork本质上还是使用child_process.fork()这个方法来创建子进程，进程间通信无非几种：pipe（管道）、消息队列、信号量、Domain Socket。Nodejs中是通过pipe(管道)实现的，pipe作用于之间有血缘关系的进程，通过fork传递，其本身也是一个进程，将一个进程的输出作为另外一个进程的输入。



### 如何对多个Worker进行请求转发

在Nodejs中使用了RoundRobin负载均衡策略，简称RP,它的实现原理是一种无状态的轮询策略，假定每台服务器的硬件资源、处理性能都是相同的，根据进程的数量，依次分配，直到所有进程处理完了，再开始重新计算分配。优点是实现起来简洁也易用，缺点是如果出现某个请求占用的时间较长，就会导致负载不会太均衡。

RP这种负载均衡技术适用于同一组服务器拥有相同的软硬件配置且平均的服务请求响应

RP是一种常见的复杂均衡技术，Nginx中也有使用，另外在RP的基础上还衍生了一个Weighted Round-Robin权重负载均衡轮询算法，简称WRR,同样也是使用轮询的技术，但是在基础上考虑了服务器的处理能力，实现时为服务器加上权重，这种负载均衡算法能够确保高性能的服务器得到更多的使用率，避免低性能的服务器负载过重。

### Nodejs负载均衡策略设置

- RoundRobin,RR。设置时要使用cluster.SCHED_RR,如果通过环境变量设置要使用rr,如果用cluster对象获取 schedulingPolicy数字表示为2
- Shared Socket，SS,设置时要用cluster.SCHED_NONE，如果通过环境变量设置要用node,如果用cluster对象获取schedulingPolicy数字表示为1

```javascript
// cluster对象的schedulingPolicy属性设置
const cluster = require('cluster');

// 策略一：一种轮询的策略，默认值
cluster.schedulingPolicy = cluster.SHCED_RR;

// 策略二:由操作系统调度的策略
cluster.schedulingPolicy = cluster.SCHED_NONE;

cluster.fork();

// 或者通过环境变量 NODE_CLUSTER_SCHED_POLICY设置：
env NODE_CLUSTER_SCHED_POLICY = 'none' node app.js 
```

## 基于Stream实现多文件合并

### 一个简单的Stream操作

创建一个可读流readable一个可写流writeable，通过管道pipe将可写流绑到可读流，一个简单的Stream操作就可以完成

```javascript
const fs = require('fs');
const readable = fs.createReadStream('./log/read.txt');
const writeable = fs.createWriteStream('./log/write.txt');

readable.pipe(writeable)

// readable.pip(destionation[,option])
// destionation：是一个可写流对象，也就是一个数据写入的目标对象
// options:end,读取结束时终止写入流，默认值是true

// 默认情况下不需要手动调用写入流的end方法关闭的，更改end为false写入的目标将会处于一直打开状态，此时就需要监听可读流的end时间，结束之后手动调用可写流的end事件。

readable.pipe(writeable,{
    end:false
});

readable.on('end',()=>{
    writeable.end('结束')
})
```

如果可读流期间发什么什么错误，则写入的目标流将不会关闭，所以需要监听错误事件，手动关闭可写流，防止内存泄露。

### 多个文件通过Stream合并成一个文件

设置可读流的end为false可以保持写入流一直处于打开状态，通过这种方式，一开始可写流处于打开状态，知道所有的可读流结束，我们再将可写流关闭。

```javascript
const fs = require('fs');
const path = require('path');

/**
 * Stream 合并
 * @param {String} sourceFiles 源文件目录名
 * @param {String} targetFile 目标文件
*/

function streamMerge(sourceFiles, targetFile) {
  const scripts = fs.readdirSync(path.resolve(__dirname, sourceFiles)); // 获取源文件目录下的所有文件
  const fileWriteStream = fs.createWriteStream(path.resolve(__dirname, targetFile)); // 创建一个可写流
  streamMergeRecursive(scripts, fileWriteStream);
}


/**
 * Stream 合并的递归调用
 * @param {Array} scripts
 * @param {Stream} fileWriteStream
*/

function streamMergeRecursive(scripts = [], fileWriteStream) {
  // 递归到尾 的情况判断
  if (!scripts.length) {
    return fileWriteStream.end("console.log('Stream 合并完成')") // 最后关闭可写流，防止内存泄露
  }
  const currentFile = path.resolve(__dirname, 'scripts/', scripts.shift());
  const currentReadStream = fs.createReadStream(currentFile); // 获取当前的可读流

  currentReadStream.pipe(fileWriteStream, { end: false });
  currentReadStream.on('end', () => {
    streamMergeRecursive(scripts, fileWriteStream)
  })

  currentReadStream.on('error', (error) => { // 监听错误事件，关闭可读流，防止内存泄露
    console.log(error);
    fileWriteStream.close()
  })
}

streamMerge('./scripts', './script.js')
```

## Stream pipe的使用与实现原理

通过流我们可以将一大块数据拆分称为一小部分一点一点的流动起来，不需要一次性全部读入，在Linux下可以通过`|`符号实现，类似的在Nodejs的Stream模块中同样也为我们提供了 pipe方法来实现

### 未使用Stream pipe的情况

在Nodejs中I/O操作都是异步的，先用util模块的promiseify方法将fs.readFile的callback形式转换为Promise形式

，它将数据一次性读入内存然后再进行返回，当数据文件很大的时候也是对内存的一种消耗，不推荐

```javascript
// koa 的例子
const Koa = require('koa');
const fs = require('fs');
const app = new Koa();
const {promisify} = require('util');
const {resolve} = require('path');
const readFile = promisify(fs.readFile);

app.use(async ctx=>{
    try{
        ctx.body = await readFile(resolve(__dirname,'test.json')))
    }catch(err){
        ctx.body = err
    }
}).listen(3000)
```

### 使用Steam pipe

```javascript
app.use(async ctx=>{
    try{
        const readable = fs.createReadStream(resolve(__dirname,'test.json'));
        ctx.body = readable;       
    }catch(err){
        ctx.body = err;
    }
})
// 在Koa中直接创建一个可读流赋值给ctx.body，框架内封装好了pipe方法，下面为源码
function respond(ctx){
    let body = ctx.body;
    if(body instanceof Stream) return body.pipe(res)
}
```

### 使用与不使用Stream

使用了可读流，通过pipe接口监听data与end事件，把data的可读流拆分称为一小块一小块的数据（chunks），像流水一样源源不断吐给客户端，而不再需要等待整个文件都加载到内存后才发送数据。pipe可以视为流的管道/通道方法，任何类型的流都会有这个方法来处理流的输入与输出。

总体来说，使用流可以大大提升响应时间，又能有效减轻服务器内存的压力

### 源码分析

在应用层调用 fs.createReadStream 方法，找到这个方法创建的可读流对象pipe的方法实现

#### /lib/fs.js

```javascript
// 导出一个createReadStream方法，在这个方法里面创建一个ReadSream可读流对象，且ReadStream来自internal/fs/streams

// 懒加载，主要在用到的时候用来实例化 ReadStream/WriteStream等对象
function lazyLoadStreams(){
    if(!ReadStream){
        ({ReadStream,WriteStream}) = require('internal/fs/streams');
        [FileReadStream,FileWriteStream] = [ReadStream,WriteStream];
    }
}

function createReadStream(path,options){
   lazyLoadStreams();
    return new ReadStream(path,options); // 创建一个可读流
}

module.exports = fs = {
    createReadStream, // 导出 createReadStream 方法
}
```

#### /lib/internal/fs/streams.js

```javascript
// 这个方法定义了构造函数 ReadStream，且在原型上定义了 open、_read、_destroy等方法，没有pipe方法，通过ObjectSetPrototypeOf方法实现了继承，ReadStream继承了Readable在原型中定义的函数，继续查找Readable的实现

const {Readable,Writeable} = require('stream');


function ReadStream(path,options){
    if(!(this instanceof ReadStream)) return new ReadStream(path,options)
    
    Readable.call(this,options)
}

ObjectSetPrototypeOf(ReadStream.prototype,Readable.prototype);
ObjectStreamProtptypeOf(ReadStream,Readable);

ReadStream.prototype.open = function(){}
ReadStream.prototype._read = function(n){}
ReadStream.prototype._destroy = function(err,cb)

module.exports = {
    ReadStream,
    WriteStream
}
```

#### /lib/stream.js

```javascript
// to avoid cross-reference(require) issue

const Stream = module.exports = require('internal/streams/legacy');

Stream.Readable = require('_stream_readable');
Stream.Writable = require('_stream_writable')
Stream.Duplex = require('_stream_duplex');
Stream.Transform = requier('_stream_transform');
Stream.PassThrough = require('_stream_passthrough');
```

#### /lib/internal/streams/legacy.js

```javascript
// 继承了Events 模块，然后在原型上定义了pipe方法，而_stream_readable继承了Stream之后又自己实现了pipe方法
const {ObjectSetPrototypeOf} = primordials;
const EE = require('events');

function Stream(opts){
   	EE.call(this,opts)
}

ObjectSetPrototypeOf(Stream.prototype,EE.prototype);
ObjectSetPrototypeOf(Stream,EE);

Stream.prototype.pipe = function(dest,options){
    // ...
}
module.exports = Stream;
```

#### /lib/\_stream\_readable.js

```javascript
// 定义了Readable构造函数，且继承于lib/stream.js的Stream，然后重写pipe方法
module.exports = Readable;
Readable.ReadableState = ReadableState;

const EE = require('events');
const Stream = require('stream');

ObjectSetPrototypeOf(Readable.prototype,Stream.prototype)
ObjectSetPrototypeOf(Readable,Stream);

function Readable(options){
    if(!(this instanceof Readable)) return new Readable(options)
    
    Stream.call(this,options); // 继承自 Stream构造函数的定义
}
```

##### \_stream\_readable.js实现分析

1.声明构造函数Readable，继承Stream的构造函数和原型。

文件继承了events事件，拥有了events在原型中定义的属性，例如on、emit

2.声明pipe方法，订阅data事件

在Stream原型上声明pipe方法，订阅data事件，src为可读对象，dest为可写流对象。在使用pipe方法的时候也是监听的data事件，一边读取一边写入数据。

ondata方法的几个核心的实现：

- dest.write(chunk):接受chunk写入数据，如果内部的缓冲小于创建流时配置的highWaterMark，则返回true（缓存未满）,否则返回false时应该停止向流写入数据，直到‘drain'（清空缓存）事件被触发
- src.pause()：可读流会停止data事件，意味着此时暂停数据写入了

调用src.pause是为了防止读入数据过快来不及写入，如果缓存未满即dest.write(chunk)，这个缓存是根据创建流时创建的highWaterMark属性，默认为16384（16k），对象模式的流默认为16

```javascript
Readable.prototype.pipe = function(dest,options){
    const src = this;
    src.on('data',ondata);
    function ondata(){
        const ret = dest.write(chunk);
        if(ret === false){
            ...
            src.pause();
        }
    }
}
```

3.订阅drain事件，继续流动数据。继续写入事件到流时会触发drain事件，也就是dest.write(chunk)等于false(缓存满了)时，如果ondrain不存在则注册drain事件

```javascript
Readable.prototype.pipe = function(dest,options){
    const src = this;
    src.on('data',ondata);
    function ondata(){
        const ret = dest.write(chunk);
        if(ret === false){
            ...
            if(!ondrain){
        		// When the dest drains, it reduces the awaitDrain counter
        		// on the source.  This would be more elegant with a .once()
        		// handler in flow(), but adding and removing repeatedly is
        		// too slow.    
                ondrain = pipeOnDrain(src);
                dest.on('drain',ondrain);
            }
            src.pause();
        }
    }
    // 当写入流dest耗尽时，它将会在可读流对象 source上减少 awaitDrain计数器，为了确保所有需要缓存的写入都完成，即state.awaitDrain === 0和src可读流上的data事件存在，切换流到流动模式
    function pipeOnDrain(src){
        return function pipeDrainFunctionResult(){
            const state = src._readableState;
            debug('pipeOnDrain',state.awaitDrain);
            if(state.awaitDrain){
                state.awaitDrain--;
            }
            if(state.awaitDrain ===0 && EE.listenerCount(src,'data')){
                state.flowing = true;
                flow(src)
            }
        }
    }
    
    // Stream.read() 从内部缓存拉取并返回数据，如果没有可读的数据，则返回null，在可读流上src还有一个readable属性，如果可以安全地调用readable,read(),则为true
    function slow(stream){
        const state = stream._readableState;
        debug('flow',state.flowing);
        while(state.flowing && stream.read() !== null)
    }
}
```

4.触发data事件。调用readable的resume方法，触发可读流的data事件，进入流动模式

```javascript
Readable.prototype.pipe = function(dest,options){
    const src = this;
    // start the flow if it hasnot been started already.
    if(!state.flowing){
        debug('pipe resume')
        src.resume();
    }
}
```

resume方法内部又调用resume\_()，最终执行了stream.read(0)读取了一次空数据（size设置为0），将会触发实例上的\_read()方法，再触发data事件。

```javascript
function resume(stream,state){
    process.nextTick(resume_,stream,state)
}

function resume_(stream,state){
    debug('resume',state.reading);
    if(!state.reading){
        stream.read(0);
    }
}
```

5.订阅end事件

end事件：当可读流中没有数据可供消费时触发，调用onend函数，执行dest.end()方法，表明已没有数据要被写入可写流，进行关闭（关闭可写流的id）,之后再调用stream.write会导致错误。

```javascript
Readable.prototype.pipe = function(dest,options){
    const doEnd = (!pipeOpts || pipeOpts.end !== false) && dest !== process.stdout &&
          dest !== process.stderr;
    const endFn = doEnd?onend:unpipe;
    if(state.endEmitted){
        process.nestTick(endFn)
    }else{
        src.once('end',endFn)
    }
    dest.on('unpipe',onunpipe)
    
    function onend(){
        debug('onend');
        dest.end();
    }
}
```

6.触发pipe事件，传入可读流对象

```javascript
Readable.prototype.pipe = function(dest,options){
    const source = this;
    dest.emit('pipe',src);
}
```

在应用层使用但的时候可以在可写流上订阅pipe事件，做一些判断。

7.支持链式调用，最后返回dest

```javascript
Stream.protptype.pipe = function(dest,options){
    return dest;
}
```

## /lib/internal/streams/legacy.js模块实现分析

### 声明构造函数Stream

声明构造函数Stream继承于事件events,此时就拥有了events在原型定义的属性，例如on/emit等方法

```javascript
const {ObjectSetPrototypeOf} = primordials;

const EE = require('events');

function Stream(opts){
    EE.call(this,opts)
}
ObjectSetPrototypeOf(Stream.prototype,EE.prototype);
ObjectSetPrototypeOf(Stream,EE)
```

### 声明pipe方法，订阅data事件

在Stream原型上声明pipe方法，订阅data事件，source为可读流对象，dest为可写流对象

在使用pipe方法的时候也是监听的data事件，一边读取数据一边写入数据

ondata方法的几个API：

- dest.writable：如果调用writable.write()是安全的，则为true
- dest.write(chunk)：接收chunk写入数据，如果内部的缓冲小于内部创建流时配置的highWaterMark，则返回true,否则返回false时应该停止向流写入数据，知道drain事件被触发。
- source.pause()：可读流会停止data事件，意味着此时暂停数据写入了

```javascript
Stream.prototype.pipe = function(dest,options){
    const source = this;
    function ondata(chunk){
        if(dest.writable && dest.write(chunk) === false && source.pause){
            source.pause();
        }
    }
    source.on('data',ondata)
}
```

### 订阅drain事件

如果调用dest.write(chunk)返回false,就会调用source.pause()停止数据流动，继续写入事件到流时会触发drain事件，ondrain方法的几个API：

- source.readable：如果可以安全地调用readable.read()，则为true,例如数据未读到末尾，则会返回true，表示可读的。
- source.resume()：将被暂停的可读流恢复触发data事件，并将流切换流动模式

```javascript
Stream.prototype.pipe = function(dest,options){
    function ondrain(){
        if(source.readable && source.resume){
            source.resume();
        }
    }
    dest.on('drain',ondrain)
}
```

### 选项指定end属性，订阅end,close事件

```javascript
// 如果end选项没有被提供，可读流订阅end或者close事件，后续将会触发该事件，指定dest.end方法，仅被调用一次，didOnEnd变量做了控制，主要是为了关闭可写流的id
// close:当流或者底层资源（比如文件描述符）被关闭时触发close事件
// end: 当可读流中没有数据可供消费的时候触发
// 可读流的end,destroy方法
// dest.end() 表明已经没有数据要被写入可写流，进行关闭，之后再调用stream.write会导致错误
// dest.destory() 销毁流
Stream.prototype.pipe = function(dest,options){
    if(!dest._isStdio && (!options || options.end !== false)){
        source.on('end',onend);
        source.on('close',onclose);
    }
    let didOnEnd = false;
    function onend(){
        if(didOnEnd) return;
        didOnEnd = true;
        dest.end();
    }
    
    function onclose(){
        if(didOnEnd) return;
        didOnEnd = true;
        if(typeof dest.destory === 'function'){
            dest.destroy();
        }
    }
}
```

### 订阅可读流与可写流的error事件

可读流、可写流发生错误时触发error事件，调用onerror方法，首先移除可读流，可写流订阅的所有事件

```javascript
Stream.prototype.pipe = function(){
    function onerror(er){
        cleanup();
        if(EE.listenerCount(this,'error') == 0){
            throw er;
        }
    }
    
    source.on('error',onerror);
    dest.on('error',onerror);
    
    function cleanup(){
        source.removeListener('data',ondata);
        dest.removeListener('drain',ondrain);
        
        source.removeListener('end',onend);
        source.removelistener('close',onclose);
        
        source.removeListener('error',onerror);
        dest.removelistener('error',onerror);
        
        source.removeListener('end',cleanup);
        source.removelistener('close',cleanup);     
        
        dest.removelistener('close',cleanup);        
    }
}
```

### 触发pipe事件

在pipe方法里面最后还会触发一个pipe事件，传入可读流对象

```javascript
Stream.prototype.pipe = function(dest,options){
    const source = this;
    dest.emit('pipe',source);
}
```

### 支持链式调用

最后返回dest,支持`A.pipe(B).pipe(c)`的写法：

```javascript
Stream.prototype.pipe = function(dest,options){
    return dest;
}
```

## util.promisify如何将Callback转换为Promise

util模块提供了很多工具函数，其中promisify方法可以将callback转换为Promise对象，解决回调地狱的问题。

### 简单实现版本

#### util promisify基本使用

将callback转为promise对象，首先确保这个callback为一个错误优先的回调函数，即`(err,value)=>err`指定一个错误参数，value为返回值

```javascript
// 创建一个text.txt文件，写入一些自定义内容，使用fs.readFile来读取这个文件进行测试
// 传统的Callback写法
const util = require('util');
fs.readFile('text.txt','utf8',(err,result)=>{
    console.log('Error',err);
    console.log('Result: ',result)
})

// Promise写法
const {promisify} = require('util');
const readFilePromisify = util.promisify(fs.readFile); // 转换为Promise

readFilePromisify('text.txt','utf8')
    .then(result=>console.log(result))
    .catch(err=>console.log(err))
```

自定义mayJunPromisify函数实现

自定义mayJunPromisify函数实现callback转换为promise，核心实现如下：

- 校验传入的参数original是否为Function,不是则抛错
- promisify(fs.readFile)执行之后会返回一个函数fn,定义待返回的函数后返回
- fn返回的是一个Promise对象，在返回的Promise对象中执行callback函数

```javascript
function mayJunPromisify(original){
    if(typeof original !== 'function'){
        throw new Error('The "original" argument must be of type Function,Received type undefined')
    }
    
    function fn(...args){
        return new Promise((resolve,reject)=>{
            try{
                original.call(this,...args,(err,result)=>{
                    if(err){
                        reject(err)
                    }else{
                        resolve(result)
                    }
                })
            }catch(err){
                resolve(result)
            }
        })
    }
    return fn;
}
```

#### util.promisify.custom基本使用

另一个功能是可以使用util.promise.custom符号重写util.promisify返回值。

在fs.readFile上定义util.promisify.custom符号，其功能为禁止读取文件

```javascript
// 注意顺序要在 util.promisify之前
fs.readFile[util.promisify.custom] = ()=>{
    return Promise.reject('该文件暂时禁止读取')
}

const readFilePromisify = util.promisify(fs.readFile);
readFilePromisify('text.txt','utf8')
    .then(result=>console.log(result))
    .catch(err=>console.log(err)) // 该文件暂时禁止读取

```

自定义mayJunPromisify.custom实现

- 定义一个Symbol变量kCustomPromisifiedSymbol赋予mayJunPromisify.custom
- 校验是否有自定义的promise函数
- 自定义的mayJunPromisified.custom也要保证是一个函数，否则抛错
- 直接返回自定义的mayJunPromisify.custom函数，后续的fn函数就不会执行了，所以在这里重写util.promisify返回值

```javascript
// 所以说util.promisify.custom是一个符号
const kCustomPromisifiedSymbol = Symbol('util,promisify.custom');
mayJunPromisify.custom = kCustomPromisifiedSymbol;

function mayJunPromisify(original){
    if(typeof original !== 'function'){
        throw new Error('The "original" argument must be of type Function,Received type undefined')
    }
    
    if(original[kCustomPromisifiedSymbol]){
        const fn = original[kCustomPromisifiedSymbol];
        if(typeof fn !== 'function'){
            throw new Error('The "mayJunPromise.custom" property must be of the type Function,Received type number')
        }
        return Object.defineProperty(fn,kCustomPromisifiedSymbol,{
            value:fn,
            enumerable:false,
            writable:false,
            configurable:true
        })
    }
    
    function fn(...args){}
    return fn;
}
```

#### util.promisify回调函数多参转换

有些函数的回调形式是多个参数的，例如dns.lookup，它的回调形式是`(err,address,family)=>...`拥有 三个参数，对这种情况也做兼容

基本使用：

```javascript
const dns = require('dns');
const lookupPromisify = util.promisify(dns.lookup);

lookupPromisify('laibh.top')
    .then(({address,family})=>{
    console.log('地址：',address,'地址族：',family)
}).catch(err=>console.log(err))
```

实现解析：

为了支持util.promisify也都会在函数上定义一个customPromisifyArgs参数，value为回调的多个参数的名称，类型为数组，例如dns.lookup绑定的customPromisifyArgs的value为`['address','family']`，其主要目的也是为了适配util.promisify

dns.lookup支持util.promisify核心实现

```javascript
const {customPromisifyArgs} = require('internal/util');

ObjectDefineProperty(lookup,customPromisifyArgs,{
    value:['address','family'],
    enumerable:false
})
```

customPromisifyArgs这个参数是从internal/util模块导出的，仅内部调用，在外部util.promisify是没有这个参数的。也就意味着只有Node模块中例如dns.lookup、fs.read等方法在多参数的时候可以使用util.promisify转换为Promise，如果自定义的callback存在多参数的情况，使用util.promisify则不行，不过可以基于util.promisify自己封装一个：

```javascript
module.exports = {
    // Symbol used to customize promisify conversion
    customPromisifyArgs:kCustomPromisifyArgsSymbol
}
```

- 定义Symbol变量kCustomPromisifyArgsSymbol
- 获取参数名称列表
- `(err,result)`改为`(err,...values)`,原先的result仅接受一个参数，改为`...values`接收多个参数
- argumentNames存在且value>1,则回调会存在多个参数名称，经常遍历，返回一个obj
- 否则values最多仅有一个参数名称，即数组values有且仅有一个元素

```javascript
const kCustomPromisifyArgsSymbol = Symbol('customPromisifyArgs');

function promisify(original){
    // 获取多个回调函数的函数参数列表
    const argumentName = original[kCustomPromisifyArgsSymbol];
    function fn(..args){
        return new Promise((resolve,reject)=>{
            try{
                original.call(this,...args,(err,...values)=>{
                    if(err){
                        reject(err)
                    }else{
                        // argumentNames存在且values>1,则回调会存在多个参数名称，进行遍历，返回一个obj
                        if(argumentNames !== undefined && values.length > 1){
                            const obj = {};
                            for(let i=0;i<argumentNames.length;i+=1){
                                obj[argumentNames[i]] = values[i];
                                resolve(obj)
                            }
                        }else{
                            // 否则values最多只有一个参数名称，即数组values有且只有一个元素
                            resolve(values[0])
                        }
                    }
                })
            }
        })
    }
    return fn;
}
```

#### 完整代码

```javascript
// 由于kCustomPromiseArgsSymbol使用Symbol声明（每次重新定义都会不一样），且没有对外提供。要实现这个功能，需要每次在cb重新定义kCustomPromisifyArgsSymbol属性

const kCustomPromisifiedSymbol = Symbol('util.promisify.custom');
const kCustomPromisifyArgsSymbol = Symbol('customPromisifyArgs');
mayJunPromisify.custom = kCustomPromisifiedSymbol;

function mayJunPromisify(original){
    if(typeof original !== 'function'){
        throw new Error('The "original" argument must be of type Function,Received type undefined')
    }
    
    if(original[kCustomPromisifiesSymbol]){
        const fn = original[kCustomPromisifiesSymbol];
        if(typeof fn !== 'function'){
            throw new Error('The "util.promisify.custom" property must be of type Function.Received type number')
        }
        return Object.defineProperty(fn,kCustomPromisifiedSymbol,{
            value:fn,
            enumerable:false,
            writable:false,
            configurable:true
        })
        // 获取多个回调函数的参数列表
        const argumentNames = original[kCustomPromisifyArgsSymbol];
        
        function fn(...args){
            return new Promise((resolve,reject)=>{
                try{
                    original.call(this,...args,(err,...values)=>{
                        if(err){
                            reject)(err);
                        }else{
                            // argumentName 存在且 values>1,则回调会存在多个参数名称，进行遍历，返回一个obj
                            if(argumentNames !== undefined && values.length > 1){
                                const obj = {};
                                for(let i=0;i<argumentNames.length;i+=1){
                                    obj[argumentNames[i]] = values[i]
                                    resolve(obj)
                                }
                            }else{
                                // 否则values最多仅有一个参数名称，即数组values有且仅有一个元素
                                resolve(values[0])
                            }
                        }
                    })
                }catch(err){
                    reject(err)
                }
            })
        }
    }
}
module.exports = {
    mayJunPromisify,
    kCustomPromisifyArgsSymbol
}
```

使用：

```javascript
const {kCustomPromisifyArgsSymbol,mayJunPromisify} = require('./may-jun-promisify');
const fs = require('fs');

// mayJunPromisify.custom自定义Promise函数测试
function promisifyCustomTest(){
    fs.readFile[mayJunPromisify.custom]=()=>{
        return Promise.reject('该文件暂时禁止读取')
    }
    const readFilePromisify = mayJunPromisify(fs.readFile);
    readFilePromisify('text.txt','utf8')
        .then(result=>console.log(result))
        .catch(err=>console.log(err)))
}

// 自定义cb多参数转换promise
function cbConverPromiseTest(){
    function getUserById(id,cb){
        const name = 'laibh',
              age = 25;
        cb(null,name,age);
    }
    Object.defineProperty(getUserById,kCustomPromisifyArgsSymbol,{
        value:['name','age'],
        enumerable:false
    })
    
    const getUserByIdPromisify = mayJunPromisify(getUserById);
    getUserByIdPromisify(1)
        .then({name,age}=>{
        console.log(name,age);
    	})
        .catch(err=>console.log(err))
    
    
}
promisifyCustomTest();
cbConverPromiseTest();
```



## I/O

I/O即Input/Output，输入输出端口，是信息处理系统与外部世界之间的通信，输入手是系统接收的信号或数据，输出的则是从其发送的信号或数据

一次I/O操作分为等待资源，使用资源两个阶段，常见的词网络I/O,磁盘I/O

### 阻塞与非阻塞I/O

是对于操作系统内核而言的，发生在等待资源阶段，根据发起的I/O请求是否阻塞来判断

阻塞I/O：这种模式下一个用户进程在发起一个I/O操作之后，只有接收到响应或者超时时才可进行处理其他事情，否则I/O将会一直阻塞。以读取磁盘上的一段文件为例子，系统内核在完成磁盘寻道、读取数据、复制数据到内存之中之后，这个调用才算完成。阻塞的这段时间对CPU资源是浪费的。

非阻塞I/O：这种模式下一个用户进程发起一个I/O操作之后，如果数据没有就绪，会立刻返回（标志数据资源不可用），此时CPU时间片可以用来做一些其他事情。

### 同步与异步I/O

同步与异步I/O发生在使用资源阶段。

同步I/O：应用发送或接受数据后，如果不返回，继续等待（此处发生阻塞），直到数据成功或失败返回。

异步I/O：应用发送或接受数据后立刻返回，数据写入OS缓存，由OS完成数据发送或接收，并返回成功或者失败的信息给应用，NodeJs就是典型异步编程的例子。

### 用户空间与内核空间

操作系统为了多个应用同时运行，需要保证不同进程相对独立、内核的安全。所以操作系统把内存空间划分为用户空、内核空间两部分。用户空间存放用户程序代码和数据，而内核空间则存放内核代码和数据。

OSI七层模型与网际网协议族图：传输层之上（会话层、表示层、应用层）为用户空间（Web客户端、浏览器、FTP），下四层（传输层，网络层，数据链路层，物理层）为内核空间，例如传输层的TCP/UDP就对应内核空间。

### 操作系统I/O模型

#### 同步阻塞IO

当进程调用 recvfrom() 函数的时候阻塞，**应用程序**开始系统调用，在**系统内核**数据就绪，将数据从内核中拷贝出来后结束。这个过程应用程序都处于等待状态，不能做其他事情，直到将数据拷贝到用户空间或出错才返回，我们称之为阻塞I/O模式。

### 同步非阻塞I/O

想对于同步非阻塞I/O模式，同步非阻塞I/O在 每次调用之后，如果数据没有就绪就会立即返回，之后重复调用检查I/O操作是否就绪，这对CPU资源非常浪费，直到数据就绪将数据从内核拷贝到用户空间，返回成功指示到应用程序。

### I/O多路复用

链接（Socket）并发大的时候，上面的两种就不适合了，前面一个处理不完，后面的就只能干等。多路复用技术先进行select数据就绪后，调用recvfrom进行真正的I/O读写操作。高级之处在于能够一个线程同时处理多个Socket

多路复用中的I/O通常指的是网络I/O,多路指的是多个Socker链接，复用指操作系统进行运算调度最小单位线程，整体的意思就是多个网络I/O复用一个或少量线程来处理Socket

I/O多路复用的四种实现：select/poll/epoll/kqueue

- select，通过轮询检查在文件描述符上设置的标志位来进行判断，select的轮询相当于在数据库中查找一条记录没有建立索引，对所有的socket进行全部遍历，这对CPU是浪费的。另外select还有一个限制，对于单个线程所能打开的文件描述符最大只有1024，那么基于select的轮询技术最多也只能很好的处理1000并发的吞吐量
- poll,poll和select在实现上没有什么本质上的区别，poll基于链表来实现，没有了最大链接1024的限制。当文件描述符多了之后，每次调用都会对链接进行线性遍历，性能也是十分低下的。
- epoll。是linux下效率最高的I/O事件通知机制，没有最大链接限制，通过callback回调通知机制，不再是每次调用对链接进行线性遍历，这样就不会随着文件描述符的增加导致效率下降。1GB内存的机器上大概能监听10w个端口，远超过select1024的限制
- kqueue，与epoll类似，仅存于FreeBSD(一种类UNIX操作系统)

### 信号驱动IO

仅在Unix上支持，与I/O多路复用相比避免了select的阻塞轮询，应用程序进行系统调用后立即返回，处理其他事情，在数据就绪之后系统会发送一个SIGIO信号到应用程序，应用程序开始读取数据

### 异步IO模型

目前最理想形式的一种，应用程序发起系统调用后无需等待直接返回当前调用状态，进行后续的其他任务，结果由内核完成I/O操作之后通过回调通知到应用程序，中间没有阻塞过程。Linux2.6增加了AIO，但是很少系统能够实现

### 轮询技术Select 与 Epoll的区别

**操作方式上**

- select采用了线性遍历来查找，链接多了之后在一个庞大的数组中每次遍历来锁定一个链接，非常消耗性能
- epoll则不需要遍历，采用的是回调机制，可以看作是一个HashTable，来锁定一个对象非常快。

**文件描述符限制**

- 对于文件描述符最大链接数select限制为1024
- epoll则没有这个限制，通常在1GB内存的机器上所能支持的连接数为10W左右。

**操作系统的支持**

目前高性能的Web服务器Nginx是基于epoll来实现高并发的

### Nodejs中的内存管理和V8垃圾回收机制

在Nodejs中，关于垃圾回收、内存释放不需要像C语言创建一个对象之后需手动创建一个delete/free的一个操作之后进行GC,Nodejs与java一样，由虚拟机进行内存自动管理。

### NodeJs中的GC

node.js是基于Chrome v8引擎的javascript运行环境，V8就是虚拟机。

### 垃圾回收内存管理实践

#### 内存泄露

node提供process.memoryUsage方法来查看当前进程内存使用情况，单位为节

- ress(resident set size)：RAM中保存的进程占用的内存部分，包括代码本身、栈、堆
- heapTotal：堆中总共申请到的内存量
- heapUsed：堆中目前用到的内存量，判断内存泄露主要以这个字节为准
- external：V8引擎内存C++对象占用的内存

```javascript
/**
*单位字节格式为MB输出
*/

const format = function(bytes)
    return (bytes/1024/1024).toFixed(2)+' MB'
}

/*
*封装print方法输出内存占用信息
*/
const print = function(){
    const memoryUsage = process.memoryUsage();
    
    console.log(
        JSON.stringify({
            res:format(memoryUsage.rss),
            heapTotal:format(memoryUsage.heapTotal),
            heapUsed:format(memoryUsage.heapUsed),
            external:format(memoryUsage.external),
        })
    )
}
```

#### 内存泄露的例子

堆用来存放对象引用类型，例如字符串、对象、在代码中创建一个Fruit存放在堆中

```javascript
// example.js
function Quantity(num){
    if(num){
        return new Array(num * 1024 * 1024)
    }
    return num;
}
function Fruit(name,quantity){
    this.name = name;
    this.quantity = new Quantity(quantity);
}

let apple = new Fruit('apple');
print();
let banane = new Fruit('banane',20);
print();
// 执行代码，aplle对象heapUsed使用仅有4.21M，而banana由于quantity属性创建了一个很大数组空间导致heapUsed飙升到164.21M。
// {"rss":"19.94 MB","heapTotal":"6.83 MB","heapUsed":"4.21 MB","external":"0.01 MB"}
// {"rss":"180.04 MB","heapTotal":"166.84 MB","heapUsed":"164.24 MB","external":"0.01 MB"}
```

#### 手动执行垃圾回收内存释放

```javascript
banana = null;
global.gc();
print(); 
// 执行 node --expose-gc xxx.js --expose-gc参数表示运行手动执行垃圾回收机制，将banana对象赋值null进行GC
// {"rss":"52.48 MB","heapTotal":"9.33 MB","heapUsed":"3.97 MB","external":"0.01 MB"}
// heapUsed的使用已经降了下来
```

### V8垃圾回收机制

垃圾回收指的是回收那些在应用程序中不再引用的对象，当一个对象无法从根节点访问这个对象就会作为垃圾回收的候选对象。这里的根对象可以为全局对象、局部变量，无法从根节点访问指的也就是不会再被其他活动对象所引用。

#### V8堆内存限制

在V8中限制64位机制大约为1.4G，32位的大概是0.7G，对于一些大内存的操作需要谨慎否则超出V8内存限制会造成进程退出

内存溢出边界的例子：

```javascript
// overflow.js
const format = function(bytes){
    return (bytes / 1024 / 1024).toFixed(2)+' MB';
}

const print = function(){
    const memoryUsage = process.memoryUsage();
    console.log(
        `heapTotal:${format(memoryUsage.heapTotal)},
		 heapUsed: ${format(memoryUsage.heapUsed)}`
    )
}

const total = [];
setInterval(()=>{
    total.push(new Array(20*1024*1024)) // 大内存占用
    print();
},1000)
```

total为全局变量每次增长大概在160M左右且不会被回收，在接近V8边界时无法分配内存导致进程内存溢出

```shell
$ node overflow.js
heapTotal: 166.84 MB, heapUsed: 164.23 MB
heapTotal: 326.85 MB, heapUsed: 324.26 MB
heapTotal: 487.36 MB, heapUsed: 484.27 MB
heapTotal: 649.38 MB, heapUsed: 643.98 MB
heapTotal: 809.39 MB, heapUsed: 803.98 MB
heapTotal: 969.40 MB, heapUsed: 963.98 MB
heapTotal: 1129.41 MB, heapUsed: 1123.96 MB
heapTotal: 1289.42 MB, heapUsed: 1283.96 MB

<--- Last few GCs --->

[87581:0x103800000]    11257 ms: Mark-sweep 1283.9 (1290.9) -> 1283.9 (1290.9) MB, 512.1 / 0.0 ms  allocation failure GC in old space requested
[87581:0x103800000]    11768 ms: Mark-sweep 1283.9 (1290.9) -> 1283.9 (1287.9) MB, 510.7 / 0.0 ms  last resort GC in old space requested
[87581:0x103800000]    12263 ms: Mark-sweep 1283.9 (1287.9) -> 1283.9 (1287.9) MB, 495.3 / 0.0 ms  last resort GC in old space requested


<--- JS stacktrace --->
```

v8提供了两个参数仅在启用阶段调整内存限制大小，分别为调整老生代、新生代：

- --max-old-space-size=2048
- --max-new-space-size=2048

内存不是越大越好，一方面是服务器资源昂贵，另外是V8以1.5G的堆内存进行一次小的垃圾回收大约需要50毫秒以上时间，会导致JavaScript进程暂停，这也是最主要的一方面。

#### 新生代与老生代

**新生代空间**

由于新空间的垃圾回收机制很频繁，所以处理方式必须非常快，采用Scavenge算法，这是一种复制算法，新生代空间会被一分为二划分为两个相等大小的from-space和to-space工作方式是将from space中存活的对象复制出来，然后移动它们到to space 中或者被提升到老生代空间中，对于from space中没有存活的对象将会被释放，完成这些复制后再将from space和to space进行互换。

Scavenge算法适用少量内存的垃圾回收，但是有很大的空间开销，对于新生代少量内存是可以接受的

**老生代空间**

新生代空间在垃圾回收满足于一定的条件（是否经过Scavenge空间、to space内存占比）会被晋升到老生代空间中，在老生代空间中的对象都已经至少经历了一次或者多次的回收所以它们的存活概率会更大。在使用Scavenge算法会有两个缺点，一是将会重复的复制存活对象使得效率低下，二是对空间资源的浪费，所以在老生代空间中采用了 Mark-Sweep（标记清除）和Mark-Compact（标记整理）算法

Mark-Sweep处理时分为标记、清除两个步骤，与Scavenge算法只复制活对象相反的是在老生代空间中由于活对象占多数Mark-Sweep在标记阶段遍历堆中的所有对象仅标记活对象把未标记的死对象清除，这时一次标记清除就已经完成了。有一个问题是被清除的对象遍布于各内存地址，产生很多内存碎片

Mark-Compact(标记整理算法)为了解决内存碎片问题，在其工作过程中将活着的对象往一端移动，这时内存空间是紧凑的，移动完成之后，直接整理边界之外的内存。

#### 小结

V8使用了不同的垃圾回收算法Scavenge/Mark-Sweep/Mark-Compact.这三种垃圾回收算法都避免不了在进行垃圾回收时需要将应用程序暂停，待垃圾回收完成之后在恢复应用逻辑，对于新生代空间来说由于很快所以影响不大，但是对于老生代空间由于存活对象较多，停顿还是会造成影响的，因此V8又新增了增量标记的方式减少停顿时间。

### 内存泄露

内存泄露（Memory Leak）是指程序中已动态分配的堆内存由于某种原因程序未释放或无法释放，造成系统内存的浪费，导致程序运行速度减慢甚至系统奔溃等严重后果。

**全局变量**，未声明的变量或挂在全局global下的变量不会自动回收，将会常驻内存直到直到进程退出才会释放，除非通过delete或者重新赋值为undefined/null解决之间的引用关系，才会被回收。

**闭包**，也是一个常见的内存泄露问题，闭包会引用父级函数中的变量，如果闭包得不到释放，闭包引用的父级变量也不会释放从而导致内存泄露

例如：

```javascript
var theThing = null;
var replaceThing = function(){
    var originalThing = theThing;
    var unused = function(){
        if(originalThing){
            console.log('hi')
        }
        theThing = {
            longStr:new Array(1000000).join('*'),
            someMethod:function(){
                console.log(someMessage)
            }
        }
    }
}
setInterval(replaceThing,1000)
```

代码运行时，每次执行replaceThing方法都会生成一个新的对象，但是之前的对象没有释放导致的内存泄露。

**慎将内存作为缓存**

通过内存来做缓存是最快的实现方式，缓存中的存储的键越多，长期存活的对象就越多，垃圾回收时将这些对象做无用功。

```javascript
// 下面一个获取用户Token的例子，memoryStore对象会随着用户数的增加而增长，当启动多个线程或者部署在多台机器会造成每个进程都保存一份，显然是资源的浪费，最好是通过Redis做共享
const memoryStore = new Map();

exports.getUserToken = function(key){
    const token = memoryStore.get(key);
    if(token && Date.now() - token.now > 2 * 60){
        return token;
    }
    
    const dbToken = db.get(key);
    memoryStore.set(key,{
        now:Date.now(),
        val:dbToken
    });
    return token;
}
```

**模块私有变量内存常驻**

加载一个模块代码之前，Nodejs会使用一个如下的函数封装器将其封装，保证了顶层的变量（var,const,let）在模块范围内，而不是全局对象。这个时候就会形成一个闭包，在require时会被加载一次，将exports对象保存在内存中，直到进程退出才会回收，这个将会导致的是内存常驻，所以避免一些没必要的模块加载，否则也会造成内存增加

```javascript
(function(exports,require,module,__filename,__dirname){
    // 模块的代码实际上在这里
})
// 所以建议对模块的引用仅在头部初次加载之后用const缓存起来，而不是在使用时每次都去加载一起。
// 推荐
const a = require('a.js');
function test(){
    a.run();
}

// 不推荐
function test(){
    require('a.js').run();
}
```

**事件反复监听**

NodeJs中对一个事件反复监听则会报下面的错误，实际上使用的EventEmitter类，包含一个listeners数组，默认为10个监听器超出这个数则会报警，用于发现内存泄露，也可以通过emitter.setMaxListeners()方法为指定的EventEmitter实例修改限制

```shell
MaxListenersExceededWarning：Possible EventEmitter memory leak detected, 11 connect added.Use emitter.setMaxListeners() to increase limit
```

**其他注意事项**

使用定时器setInterval时记得使用对应的clearInterval进行清除。因为setInterval执行完之后会返回一个值且不会自动释放，另外还有map/filter等对数组进行操作，每次操作之后都会创建一个新的数组，将会占用内存，如果单纯的遍历map可以用forEach。

## 插件

### 缓存

- `[Cache]` [memory-fs 将文件写入内存](https://github.com/webpack/memory-fs)
- `[Cache]` [Memory Cache](https://github.com/ptarjan/node-cache#readme)
- `[Cache]` [Node Cache](https://github.com/mpneuried/nodecache)

### 定时任务

- `[Schedule]` [node-schedule](https://github.com/node-schedule/node-schedule)
- `[Schedule]` [Agenda 将Node中的定时任务存储在数据库中（官方推荐MongoDB）](https://github.com/agenda/agenda)
- `[Schedule]` [Node.js结合RabbitMQ延迟队列实现定时任务](https://www.nodejs.red/#/docs/microservice/rabbitmq-base?id=rabbitmq延迟队列实现定时任务)

### 模板引擎

- `[Template]` [Ejs](https://ejs.co/)
- `[Template]` [Handlebarsjs](https://handlebarsjs.com/)
- `[Template]` [Jade](http://jade-lang.com/)