---
title: NodeJs回顾
date: 2020-06-19  16:46:38
tags: NodeJs
categories: 
	- NodeJs
---




# NodeJS

## 模块与文件

### require 的加载机制

#### 模块的分类

系统模块

- C/C++模块，也叫build-in内建模块，一般用于native模块嗲用，在require出去
- native模块，在开发中使用的Node.js 的 http/buffer/fs等，底层也是调用的内建模块（C/C++）

第三方模块：

非Node.js自带的模块被称为第三方模块，会分成路径形式的文件模块（以`.`、`..`、`/`开头的）和自定义的模块（比如express/koa/moment.js等）

在 Node.JS 中模块加载一般会经历3个步骤：路径分析、文件定位、编译执行

按照模块的分类，按照以下的顺序进行优先加载：

- 系统缓存：模块被执行之后会进行缓存，首先是先进行缓存加载，判断换粗中是否有值。
- 系统模块：也就是原生模块，优先级次于系统缓存，部分核心模块已经被编译成二进制，省略了路径分析、文件定位，直接加载在内存中，系统模块定义在 Node.js 源码的lib目录下。
- 文件模块：优先加载 `.`、`..`、`/`开头的，如果文件没有加上拓展名，会依次按照`.js`、`.json`、`.node`尝试进行拓展名补足。（在尝试过程中也是以**同步阻塞模式**来判断文件是否存在的，从性能优化角度来看，`.json`、`node`最好还是加上文件的拓展名）
- 目录作为模块：文件模块加载过程中没有找到，但发现这是一个目录，这个适合就会把这个目录当做一个包来处理，Node采用了commonjs规范，会先在项目的根目录查找package.json文件，取出文件中定义的main属性描述的入口文件进行加载，也没有加载到，则会抛出默认错误：Error：Cannot find module 'lib/hello.js'
- node_modules目录加载：对于系统模块，路径文件模块都找不到，Nodejs会从当前模块的父目录进行查找，直到系统的根目录

### module.exports 与 exports 的区别

exports相当于 module.exports 的快捷方式：

```js
const exports = module.exports 
```

但是不能改变 exports 的指向，我们可以通过 `exports.test = 'a'`，这样来导出一个对象，但是不能通过下面的例子直接赋值，这样会改变 exports 的指向

```js
// 错误的写法，将会得到 undefined
exports = {
   'a':1,
   'b':2 
}

// 正确的写法
modules.exports ={
   'a':1,
   'b':2 
}
```



### 模块循环引用问题

```js
// a.js
console.log('a模块start');
exports.test = 1;
undeclaredVariable = 'a模块为声明变量'
const b = require('./b');
console.log('a模块加载完毕：b.test值',b.test);

// b.js 
console.log('b模块start');
exports.test = 2;
const a = require('./a');
console.log('undeclaredVariable:',undeclaredVariable)
console.log('b模块加载完毕：a.test值：',a.test)
```

执行 `node a.js`,结果：

```shell
a模块start
b模块start
undeclaredVariable:a模块未声明变量
b模块加载完毕：a.test值：1
a模块加载完毕：b.test值：2
```

启动a.js会加载b.js，那么在b.js中又加载到了a.js，但是此时a.js模块hi阿咩有执行完，返回的是一个a.js模块的exports对象未完成的副本给到b.js模块（因此不会陷入死循环），然后b.js完成加载之后将exports 对象退供给a.js模块

#### a 模块中的 undeclaredVariable 变量在 b.js 是否会打印？

undeclaredVariable 是一个未声明的变量，也就是一个挂在全局的变量，那么在其他地方是可以拿得到的

#### 假设有 a.js、b.js 两个模块相互引用，会有什么问题，会不会陷入死循环？

不会陷入死循环

## Buffer

### Buffer与Cache的区别

#### 缓冲（Buffer）

缓冲是用于处理二进制流数据，将数据存储起来，它是临时性的，对于流式数据来说，会采用缓冲区将数据临时存储起来，等缓冲到一定大小的时候存入硬盘中。视频播放器就是一个经典例子。

#### 缓存（Cache）

缓存可以看做一个中间层，可以是永久性的将热点数据进行缓存，使得访问速度更快。例如我们通过对 memory、Redis等将数据从硬盘或者第三方接口中请求过来进行缓存，目的就是将数据存于内存的缓存区中，这样对同一个资源进行访问，速度会更快，也就是性能优化的一个重要点。



## 线程与进程

#### 什么是进程（Process）和线程（Thread），之间的区别

##### 进程

进程是计算中程序关于数据集合上的一次运行活动，是系统进行资源分配和调度的基本单位，是操作系统结构的基础，进程是线程的容器。启动一个服务，运行一个实例，就是开一个服务进程。多进程就是进程的复制（fork），fork出来的每个进程都有自己的独立空间地址、数据栈，一个进程无法访问另外一个进程里定义的变量、数据结构，只有建立了IPC通信，进程之间才可以数据共享。

##### 线程

线程是操作系统能够进行运算调度的最小单位，线程是隶属进程的，被包含与进程之中的。一个线程只能隶属一个进程，但是一个进程是可以拥有多个线程的。



同一个代码，可以根据系统CPU核心数启动多个进程，每个进程都有属于自己的独立运行空间，进程之间是不互相影响的。同一进程中的多条线程将共享该进程中的全部系统资源，如虚拟地址空间，文件描述和信号处理等。但 同一进程中的多个线程有各自的调用栈，自己的寄存器环境，自己的线程本地存储。



### 什么是孤儿进程

父进程创建子进程之后，父进程退出了，但是父进程对应的一个或者多个子进程还在运行，这些子进程会被系统的init进程收养，对应的程序ppid为1，这就是孤儿进程。



### 创建多进程时，代码里有`app.listen(port)`在进行fork时，为什么没有报端口被占用

端口被占用的情况：

```js
// master.js
const fork = require('child_process').fork;
const cups = require('os').cups();

for(let i=0;i<cups.length;i++){
    const worker = fork('worker.js')
    console.log('worker process created, pid: %s ppid: %s', worker.pid, process.pid);
}

// worker.js
const http = require('http');
http.createServer((req,res)=>{
    res.send('I am worker,pid:'+process.pid+', ppid: '+process.pid)
}).listen(3000);

// 控制台执行node master.js只有一个worker 可以监听 3000 端口，其余会抛出 Error:listen EADDRINUSE :::3000错误
```

多进程模式可通过句柄传递不会有端口占用的问题。

当父子进程之间建立IPC通道之后，通过子进程对象的send方法发送消息，第二个参数sendHandle就是句柄，可以是TCP套接字，TCP服务器、UDP套接字等，为了解决上面多进程端口占用问题，将主进程的socket传递到子进程：

```js
// master.js
const fork = require('child_process').fork;
const cups = require('os').cpus();
const server = require('net').createServer();
server.listen(3000);
process.title = 'node-master';

for(let i=0;i<cpus.length;i++){
    const worker = fork('worker.js')
    worker.send('server',server);
    console.log('worker process created, pid: %s ppid: %s', worker.pid, process.pid);
    
    if(i+1 === cpus.length){
        console.log('serve close');
        server.close(); // 关闭服务器监听，交由子进程处理
    }
}

// worker.js
const http = require('http');
const server = http.createServer((req,res)=>{
    res.end('I am worker, pid: ' + process.pid + ', ppid: ' + process.ppid);
})
let worker;
process.title = 'node-worker';
process.on('message',(message,sendHandle)=>{
    if(message === 'server'){
        worker = sendHandle;
        worker.on('connection',(socket)=>{
            server.emit('connection',socket)
        })
    }
})
```



### 什么是IPC通信，如何建立，什么场景下会使用

IPC(inter-process communication)，即进程间通信技术，由于每个进程创建之后都有自己的独立地址空间，实现IPC的目的就是进程之间的资源共享访问，实现IPC的方式有多种：管道、消息队列、信号量、Domain Socket，Nodejs通过pipe来实现。

未使用IPC的情况：

```javascript
// pipe.js
const spawn = require('child_process').spawn;
const child = spawn('node',['worker.js']);
console.log(process.pid,child.pid);

// worker.js
console.log('I am worker,PID:',process.pid)

// 执行 node pipe.js，输出主线程的id，子线程的id，但是子线程worker.js的信息没有在控制台打印，原因是新创建的子进程有自己的 stdio流
```

创建一个父进程和子进程之间传递消息的IPC通道实现输出信息

```javascript
// 修改pipe.js让子进程的stdio和当前进程的stdio之间建立管道链接，还可以通过spawn方法的stdio选项建立IPC机制
// pipe.js
const spawn = require('child_process').spawn;
const child = spawn('node',['worker.js']);
child.stdout.pipe(process.stdout);
console.log(process.pid,child.pid);

// 父进程与子进程的通信
// 父进程在创建子进程之前会先去创建IPC通道并一直监听该通道，之后开始创建子进程并通过环境变量（NODE_CHANNEL_FD）的方式将IPC频道的文件描述符传递给子进程，子进程启动时根据传递的文件描述符去链接IPC通道，从而建立父子进程之间的通信机制。
```



### Node.js是单线程还是多线程，为什么会单线程

javascript是单线程，在服务端运行环境的nodejs不是单线程。

浏览器环境中对于DOM的操作是单线程的，避免DOM渲染冲突，在浏览器中UI渲染线程和JS执行引擎是互斥的，一方在执行式都会导致另一方被挂起，这是由JS引擎所决定的。

### 关于守护进程，是什么，为什么，怎么编写？

守护进程运行在后台不受终端影响。

#### 创建步骤

1. 创建子进程
2. 在子进程中创建新会话（调用系统函数setsid）
3. 改变子进程工作目录（如：’/‘或者’/usr/‘等）
4. 父进程终止

### 编写demo

```javascript
// index.js文件的处理逻辑使用 spawn创建子进程完成第一步，设置options.detached为true可以使得子进程在父进程退出后继续运行（系统层会调用setsid方法），这是第二步。options.cwd指定当前子进程工作目录不做设置默认继承当前工作目录，这是第三步。运行daemon.unref()退出父进程，第四步。
// index.js
const spawn = require('child_process').spawn;

function startDaemon(){
    const daemon = spawn('node',['daemon.js'],{
        cwd:'/usr',
        datached:true,
        stdio:'ignore',
    })
    console.log('守护进程开启 父进程 pid: %s, 守护进程 pid: %s', process.pid, daemon.pid);
    daemon.unref();
}
startDaemon();

// daemon.js文件哩逻辑开启一个定时器每10秒运行一次，使得这个资源不会退出，同时写入日志到子进程当前的工作目录下
// /usr/daemon.js
const fs = require('fs');
const {Console} = require('console');

const logger = new Console(fs.createWriteStream('./stdout.log'),fs.createWriteStream('./stderr.log'));

setInterval(function(){
    logger.log('daemon pid:',process.pid,'ppid: ',process.ppid)
},1000*10)
```

实际工作中守护进程很多，例如PM2,Egg-Cluster等，实际工作上对于守护进程的健壮性要求还是很高的，例如：进程的异常监听，工作进程管理调度，进程挂掉之后重启等等。

### 实现一个简单的命令行交互程序

采用子进程 child_process的spawn方法：

```javascript
const spawn = require('child_process').spawn;
const child = spawn('echo',['简单的命令行交互']);
child.stdout.pipe(process.stdout) // 将子进程的输出作为当前进程的输入，打印在控制台
```



### 进程的当前工作目录是什么，有什么用

进程的当前工作目录可以通过process.cwd()命令获取，默认为当前启动的目录，如果是创建子进程则继承于父进程的目录，可以通过process.chdir()命令重置，例如通过spawn命令创建的子进程可以指定cwd选项设置子进程的工作目录。

有什么用，例如fs读取文件，如果设置为相对路径则是相当于当前进程启动的目录进行查找，所以，启动目的设置有误的情况下将无法得到正确的结果。还有一种情况程序里引用第三方模块也是根据当前进程启动的目录来进行查找的

### 多进程或者多个Web服务之间的状态共享问题

多进程模式下各个进程之间是相互独立的，例如用户登录之后seesion的保存，如果保存在服务进程里，那么如果我有4个工作进程，每个进程都要保存一份这是没有必要的。假设服务重启了数据也会丢失。多个Web服务也是一样的，还会出现在A机器创建了Session，当负载均衡分到B机器上之后还需要再创建一份，一般的做法是通过Redis或者数据库来做数据共享

### 什么是僵尸进程

使用fork可以创建子进程，正常情况进程退出，内核要释放进程所占用的资源：打开的文件、占用的内存等，但是进程的PID、退出状态、运行时间等会进行保留，知道父进程调用wait/waitpid来获取子进程的状态信息时，这些资源才会释放。

如果子进程退出之后，父进程没有调用wait/waitpid来获取子进程的状态，那么保留的进程号将会一直被占用，且占用系统资源，称为僵死或僵尸进程。

元凶是其父进程，我们把元凶kill掉之后，僵尸进程会变为孤儿进程被系统的 init 进程pid=1的进程所收养，init进程会对这些孤儿进程进行管理（调用wait/waitpid）释放其占用资源。

## Console

### console是异步还是同步的

console既不是总是同步的，也不总是异步的，是否为同步取决于链接是什么流以及操作系统是Window还是Posix

同步写将会阻塞实践循环直到写完成。

- 文件（Files）：Windows和POSIX平台都是同步
- 终端（TTYS）：Windows平台下同步，在POSIX平台下异步
- 管道（Pipes）：Windows平台下同步，POSIX平台下异步

### 如何实现一个console.log

可利用 process.stdout将输入流数据输出到输出流（即输出到终端）

```javascript
process.stdout.write('xxx'+'\n')
```

### 为什么console.log()执行完就退出

一旦产生事件循环，就会长产生一个While(true)的死循环，例如定时器，console.log则没有产生watch/handlers，在事件循环一次就退出了。

Nodejs进程退出会等待异步处理完成，常见的运维过程中会碰到需要进程优雅退出的场景，Nodejs自然退出是最好的，process.exit是比较粗暴的。

常见的异步请求：

- http请求，数据库请求等IO请求操作
- net.Server.listen()或者http.Server.listen等端口监听
- fs.write()类型的文件IO操作
- console.log()输出日志
- setTimeout()/setInterval等定时器操作
- process.send()等异步请求发送

## Net模块

| OSI七层模型 | TCP/IP五层模型 | 描述                                                         |
| ----------- | -------------- | ------------------------------------------------------------ |
| 应用层      | 应             | 构建于传输层之上常用的HTTP、FTP文件传输协议、SMTP邮件传输协议等 |
| 表示层      | 用             | 构建于传输层之上常用的HTTP、FTP文件传输协议、SMTP邮件传输协议等 |
| 会话层      | 层             | 构建于传输层之上常用的HTTP、FTP文件传输协议、SMTP邮件传输协议等 |
| 传输层      | 传输层         | 向用户提供可靠的端到端服务TCP、UDP                           |
| 网络层      | 网络层         | IPV4、IPV6                                                   |
| 数据链路层  | 数据链路层     | 设备驱动和硬件                                               |
| 物理层      | 物理层         | 设备驱动和硬件                                               |



### 什么是TCP协议，什么时候会选择TCP协议

IP协议是无连接通信协议，IP协议不会占用两个设备之间通信的线路，IP实际上主要负责将每个数据包路由至目的地，但是IP协议没有能确保数据包是否到达，传过去的数据是否按照顺序排列，所以IP数据包是不可靠的。而解决数据不可靠的问题就是由TCP协议来完成。

TCP（Transmission Control Protocol）是可靠的传输控制协议，三个特点：

- 面向链接：需要对方主机在线，并建立链接
- 面向字节流：发送多少字节自己说了算，每次选出一段字节发送的时候，都会带上一个序号，这个序号就是发送的这段字节中编号最小的字节的编号。
- 可靠：保证数据有序的到达对方主机，每发送一个数据就会期待收到对方的回复，在指定时间内收到了ACK回复，就确认数据到达，如果超过一定的时间没有收到对方的回复，就认为对方没有收到，再重新发送一次。

TCP报文

| 源端口（16）                                                 | 目的端口（16）   |
| ------------------------------------------------------------ | ---------------- |
| TCP序号（32）                                                | TCP序号（32）    |
| 捎带的确认（32）                                             | 捎带的确认（32） |
| 首部长度（4）保留（6）Flag（6：URG、ACK、PSH、RST、SYN、FIN） | 窗口尺寸（16）   |
| TCP校验和（16）                                              | 紧急指针（16）   |
| 数据包内容                                                   | 数据包内容       |

6个标志位：

- URG,紧急指针标志，当为1时表示紧急指针有效，为0时则忽略紧急指针
- ACK,确认序号标志，为1表示确认有效，为0表示报文不含有确认信息，确认号无误
- PSH,push标志，当为1时就是让接收方收到该TCP报文的时候不进入缓冲区排队而是快速发送给应用程序
- RST,重置连接标志，当连接出现错误的时可以重置，或者用于拒绝非法的报文段和连接请求
- SYN,同步序号，用于建立连接过程
- FIN,finish标志，用于释放连接

3次握手协议：

1. 第一次握手，当客户端需要去建立连接时，客户端就会发送SYN包（seq=x）到服务器，然后客户端进入SYN_SEND的状态，代表已经发SYN包过去，并且在等待服务器确认。此时，ACK=0,SYN=1。
2. 第二次握手，服务器收到SYN包，会进行确认，由上面的标志知道SYN是表示同步序号，这时候会使得 确认号=序号+1，即ack等于x+1,然后服务器也会像客户端发送一个SYN包（seq=y),也就是服务器会发送SYN+ACK包，来表示确认到了客户端的一次握手并且二次握手建立，此时服务器进入SYN_RECV状态。此时，ACK=1,SYN=1。
3. 第三次握手，客户端收到服务器的SYN+ACK包，然后就会向服务器发送确认包ACK(ack=y+1)和SYN(seq=x+1),等到这个包发送完毕之后客户端和服务器就会进入ESTABLISHED状态，完成三次握手，就可以在服务器与客户端之间传输数据了。

SYN是同步序号，当SYN=1而ACK=0时表明这是一个连接请求报文，对方若同意连接，那应在报文中使SYN=1和ACK=1，因此SYN置1表示这是一个连接请求或者连接接受报文。而ACK状态是用来确认是否同意连接。也就是传了SYN,证明发送方到接收方的通道没有问题，但是接收方到发送方的通道还需要ACK信号来验证

当在传送完数据之后，客户端与服务器端之间有四次握手协议：

1. 第一次握手：客户端发送一个FIN和序号过去（seq=u）用来表示客户端和服务端之间有关闭的请求，同时关闭客户端的数据传送，客户端就进入FIN_WAIT_1的状态
2. 第二次握手：服务端收到FIN=1的标志位，就会发送一个ACK标志位表示确认，然后确认序号就变成了收到的序号+1,即ack=u+1(FIN和SYN在这点相同，但是作用不一样)这时候服务端进入CLOSE_WAIT状态，这是一个半关闭状态。只能服务端给客户端发送数据而客户端不能给服务端发送数据
3. 第三次握手：这次握手还是服务端发起的。这是服务端在传完最后的数据（没有就不传）就会发送一个FIN=1和ACK=1,且序号seq会改变（没有传数据则不变），而ack不变，这时候服务端就会进入LAST_ACK状态，表示最后再确认一次。
4. 第四次握手：客户端在接收到FIN之后，就会进入TIME_WAIT状态，接着发送一个ACK和seq=u+1,ack=w+1给服务端，这时候服务端就会进入CLOSED状态。而客户端进入TIME_WAIT状态的时候必须要等待2MSL的时间才会关闭

TIME_WAIT状态的作用？（MSL：网络中数据报文存在的最大时间）

1. TIME_WAIT状态可以确保有足够的时间让对方接收到ACK包，如果ACK没有到达，在传输过程丢失了或者一些其他原因，这样就可以让客户端重发ACK包，如果客户端直接关闭了，那么就有可能导致服务端在一些情况下没有接受到ACK包而无法与客户端断开连接。这样客户端发送ACK包到服务端，服务端请求重发，一来一回就刚好是2MSL
2. 保证迟来的TCP报文段有足够的时间被识别并丢弃，linux中一个TCPort不能打开两次或者两次以上。当client处于time_wait状态时无法使用此port建立新连接，假设不存在time_wait状态，新连接可能会受到旧连接的数据

### TCP粘包是什么,该怎么办

客户端（发送一端）在发送之前会将短时间有多个发送的数据块缓冲到一起（发送缓冲区），形成了一个大的数据块一并发送，同样接收端也有一个接收缓冲区，收到的数据先存放在接收端缓冲区，然后程序从这里读取部分数据进行消费，这样做也是为了减少I/O消耗达到性能优化。

数据达到缓冲区什么时间开发发送这个取决于TCP拥塞控制，是任何时刻内确定能被发送出去的字节数的控制因素之一，是阻止发送方至接收方之间的链路变得拥塞的手段

TCP粘包解决方案：

1. 延迟发送：设置延迟发送，sleep休眠一段时间。简单但是传输效率大大降低，只适用于交互频率低的情况

2. 关闭nagle算法。nagle算法是一种改善网络传输效率的算法，避免网络中充斥着大量小的数据块，它所期望的是尽可能发送大的数据块，因此在每次请求一个数据块给TCP发送时，TCP并不会立即执行发送，而是等待一小段时间进行发送。

   当网络中充斥着大量小的数据块时，Nagle算法能将小的数据块集合起来一起发送减少了网络拥堵，但并不是所有场景都需要这样。例如，REPL终端交互，当用户输入单个字符以获取响应，所以在nodejs中可以设置 socket.setNoDelay方法来关闭Nagle算法。`const server = net.createServer(); server.on('connection',socket=>{socket.setNoDelay(true)})`

3. 封包/拆包。使用长度编码的方式，通信双方约定好格式，将消息分为定长的消息头（Header）和不定长的消息体（Body），在解析时读取消息头获取到内容的占用的长度，之后读取到的消息体内容字节数等于字节头的字节数时，认为它是一个完整的包。

| 消息头序号（Header） | 消息体长度（Header） | 消息体（Body） |
| -------------------- | -------------------- | -------------- |
| SerialNumber         | bodyLength           | body           |
| 2字节                | 2字节                | N字节          |

Buffer的几个api：

- Buffer.alloc(size[,fill[,encoding]]),初始化一个size大小的Buffer空间，默认填充0，也可以指定fill进行自动以填充
- Buffer.writeInt16BE(value[,offset]),value为要写入的Buffer值，offset为偏移量从哪个位置开始写入
- Buffer.writeInt32BE(value[,offset]),value为要写入的Buffer值，不同的是writeInt16BE表示高位优先写入一个16位整型，这个是32位
- Buffer.readInt16BE([offset])，高位优先读取16位整型，offset为读取之前要跳过的字节数
- Buffer.readInt32BE([offset])，高位优先读取32位整型，offset为读取之前要跳过的字节数

#### 编码/解码的实现

TCP顶层是基于二进制数据，应用层通常是易于表达的字符串、数字等，需要先将数据通过Buffer转换为二进制，取出的时候同样需要解码操作。

```javascript
// transcoder.js
class Transcoder {
  constructor() {
    this.packageHeaderLen = 4; // 包头长度
    this.serialNumber = 0; // 定义包序号
    this.packageSerialNumberLen = 2; // 包序列号所占用的字节
  }
  /**
   * 编码
   * @param {Object} data Buffer 对象数据
   * @param {Int} serialNumber 包序号，客户端编码时自动生成，服务器解码之后在编码时需要传入解码的包序号
  */

  encode(data, serialNumber) {
    const body = Buffer.from(data);
    const header = Buffer.alloc(this.packageHeaderLen);
    header.writeInt16BE(serialNumber || this.serialNumber);
    header.writeInt16BE(body.length, this.packageSerialNumberLen); // 跳过包序号的前两位

    if (serialNumber === undefined) {
      this.serialNumber++;
    }
    return Buffer.concat([header, body])
  }

  /**
   * 解码
   * @param {Object} buffer
  */

  decode(buffer) {
    const header = buffer.slice(0, this.packageHeader); // 获取包头
    const body = buffer.slice(this.packageHeaderLen); // 获取包尾部

    return {
      serialNumber: header.readInt16BE(),
      bodyLength: header.readInt16BE(this.packageSerialNumberLen), // 因为编码阶段跳过两位，所以解码也需要跳过
      body: body.toString(),
    }
  }

  /**
   * 获取包长度两种情况
   * 1. 如果当前buffer长度数据小于包头，肯定不是一个完整的数据包，因此直接返回0不做处理（可能数据还没有接收完）
   * 2. 否则返回这个完整的数据包长度
   * @param {*} buffer
  */

  getPackageLength(buffer) {
    if (buffer.length < this.packageHeaderLen) {
      return 0;
    }
    return this.packageHeaderLen + buffer.readInt16BE(this.packageSerialNumberLen)
  }
}


module.exports = Transcoder;
```

客户端

```javascript
const net = require('net');
const Transcoder = require('./transcoder');

const transcoder = new Transcoder();

const client = net.createConnection({
  host: '127.0.0.1',
  port: 3000
})

let overageBuffer = null; //上一次Buffer剩下的数据


client.on('data', buffer => {
  if (overageBuffer) {
    buffer = Buffer.concat([overageBuffer, buffer])
  }

  let packageLength = 0;

  // eslint-disable-next-line no-cond-assign
  while (packageLength = transcoder.getPackageLength(buffer)) {
    const packageData = buffer.slice(0, packageLength); // 取出整个数据包
    buffer = buffer.slice(packageLength); // 删除已经取出的数据包，这里采用的方法是把缓冲区（buffer）已取出的包给截掉
    const result = transcoder.decode(packageData); // 解码
    console.log(result)
  }

  overageBuffer = buffer; // 记录剩余不完整的包
}).on('error', err => { // 监听一个未开启的端口就会报 ECONNREFUSED错误
  console.log(`服务器异常: ${err}`)
}).on('close', err => {
  console.log(`客户链接断开！， ${err}`)
})

client.write(transcoder.encode('Nodejs 技术栈'))

const arr = [
  '1 JavaScript ',
  '2 TypeScript ',
  '3 Python ',
  '4 Java ',
  '5 C ',
  '6 PHP ',
  '7 ASP.NET ',
];

setTimeout(() => {
  for (let i = 0; i < arr.length; i++) {
    console.log(arr[i])
    client.write(transcoder.encode(arr[i]))
  }
}, 1000)
```

服务端

```javascript
const net = require('net');
const Transcoder = require('./transcoder');
const transcoder = new Transcoder();
const HOST = '127.0.0.1';
const PORT = 3000;
let overageBuffer = null; // 上一次善剩余数据

// 创建一个TCP服务实例
const server = net.createServer();

// 监听端口
server.listen(PORT, HOST)

server.on('listening', () => {
  console.log(`服务已经开启在${HOST}:${PORT}`)
}).on('connection', socket => {
  // data事件就是读取数据
  socket.on('data', buffer => {
    if (overageBuffer) {
      buffer = Buffer.concat([overageBuffer, buffer])
    }
    let packageLength = 0;
    // eslint-disable-next-line no-cond-assign
    while (packageLength = transcoder.getPackageLength(buffer)) {
      const packageData = buffer.slice(0, packageLength); //取出整个数据包
      buffer = buffer.slice(packageLength); // 删除取出的数据包，这里采用的方法是把缓冲区buffer已取出的包截掉
      const result = transcoder.decode(packageData); // 解码
      console.log(result);
      socket.write(transcoder.encode(result.body, result.serialNumber))
    }
    overageBuffer = buffer; // 记录不完整的包  
  }).on('end', () => {
    console.log('socket end')
  }).on('error', error => {
    console.log('socket error', error)
  })
}).on('close', () => {
  console.log('Server Close!')
}).on('error', err => {
  if (err.code === 'EADDRINUSE') {
    console.log('地址正被使用，重试中......')

    setTimeout(() => {
      server.close();
      server.listen(PORT.HOST)
    }, 1000)
  } else {
    console.log(`服务器异常: ${err}`)
  }

})

```

## DNS

DNS模块是基于UDP协议来实现的，在Nodejs中可以通过`require('dns')`实现域名的解析查询，Nodejs DNS模块分成两大类：

1. 底层操作系统工具进行域名解析
2. 链接到一个DNS网络服务器执行域名解析

### 底层操作工具域名解析

```javascript
// Nodejs DNS模块的 dns.lookup()方法使用底层操作系统进行域名解析，是不需要经过网络通信的
const dns = require('dns');

dns.lookup('laibh.top',(err,address,family)=>{
    console.log(`地址: ${address},地址族：${family}`)
})
```

### 链接到DNS服务器执行域名解析

```javascript
// dns 模块除了 dns.lookup之外的函数，都会连接到实际DNS服务器以执行名称解析并始终使用网络执行DNS查询
const dns = require('dns');
dns.lookup('laibh.top',(err,records)=>{
    console.log(records)
})
```



`dns.lookup与dns.resolve`不同

虽然用异步的角度来使用dns.lookup，但是内部的libuv底层线程池中确实同步的调用 getaddrinfo(3)，所以可能有由于一些不确定的因素造成Node进程阻塞

与dns.lookup不同的是dns.resolve没有使用getaddrinfo(3)，而通过网络执行的DNS查询，始终保持异步不会对其他进程产生负面影响

### DNS域名解析过程

1. 浏览器DNS缓存。访问一个URL优先查找浏览器的DNS缓存，命中就返回。未命中就继续下一步，查找操作系统的缓存。当修改了本地hosts域名指向发现浏览器缓存没有变化是因为每个浏览器有一个固定值。
2. 系统（OS）缓存。查看操作系统中是否有域名对应的IP,位于操作系统的hosts文件。
3. 路由器缓存。当浏览器DNS与系统OS缓存均没有映射的时候，则请求会发送到路由器缓存中检查
4. ISP DNS缓存。ISP为互联网服务提供商。

DNS本地解析指的是系统缓存这一阶段，在浏览器缓存没有命中的情况下， 会从本地系统的一个hosts文件中寻找对应的IP

## Cluster （集群）

在PM2的配置文件中可以设置`exec_model:'cluster`和`instance`两个属性来设置开启多个进程，PM2其实就是利用Nodejs Cluster这个模块来实现的，还有eggJs中的egg-cluster模块在启用Worker进程也是用到这个模块。

```javascript
const cluster = require('cluster');
const http = require('http');
const numCPUs = require('os').cpus().length;

if (cluster.isMaster) {
  console.log(`Master 进程 ${process.pid} 正在运行`)

  for (let i = 0; i < numCPUs; i++) {
    cluster.fork();
  }

  cluster.on('exit', (worker, code, signal) => { console.log(`Worker ${worker.process.pid} 已退出`) });
} else {
  http.createServer((req, res) => {
    res.send(`你好，哈哈哈 ${process.pid}`)
  }).listen(8000);
  console.log(`Worker 进程 ${process.pid} 已启用`)
}
```

### 采用了哪种集群方式

集群模式通常实现有两种：

1. 1个Node实例开启多个端口，通过反向代理服务器向各端口服务进行转发
2. 1个Node实例开启多个进程监听同一个端口，通过负载均衡技术分配请求（Master->Worker）

第一个方案存在的一个问题就是占用多个端口，造成资源浪费，由于多个实例是独立运行的，进程间通信不太好做。好处是稳定性高，各实例之间没有影响。

第二个方案多个Node进程去监听同一个端口，好处是进程间通信相对简单，减少了端口的资源浪费，但是这个时候需要保证服务进程的稳定性，特别是对Master进程稳定性要求会更高，编码也会复杂。

Nodejs中自带的Cluster模块正是采用了第二种方案。

### 多个进程为什么可以监听同一个端口

端口不是被所有的进程全部监听，仅仅受到Master进程的监听。Master进程创建一个Socket并绑定监听到目标端口，通过子进程之间建立IPC通道之后，通过调用子进程的send方法，将Socket（链接句柄）传递过去。（Master通过cluster.fork方法创建的，本质上还是使用了child_process.fork这个方法）



使用 child_process.fork()创建的子进程，进行Socket传递的示例

```javascript
// master.js
const fork = require('child_process').fork;
const cpus = require('os').cpus();
const server = require('net').createServer().listen(3000);

for (let i=0; i<cpus.length; i++) {
    const worker = fork('worker.js');
      // 将 Master 的 server 传递给子进程
    worker.send('server', server);
    console.log('worker process created, pid: %s ppid: %s', worker.pid, process.pid);
}
// worker.js
const http = require('http');
const server = http.createServer((req, res) => {
    res.end('I am worker, pid: ' + process.pid + ', ppid: ' + process.ppid);
});

let worker;
// 第二个参数 sendHandle 就是句柄，可以是 TCP套接字、TCP服务器、UDP套接字等
process.on('message', function (message, sendHandle) {
    if (message === 'server') {
        worker = sendHandle;
        worker.on('connection', function(socket) {
            server.emit('connection', socket);
        });
    }
});
```

端口会被主进程绑定监听一次，但是主进程和子进程在建立IPC通信之后，发送Socket到子进程实现端口共享，在之后Master接受到新的客户端链接后，通过负载均衡技术再转发到各Worker进程。



### 多个进程之间如何通信

由于cluster.fork本质上还是使用child_process.fork()这个方法来创建子进程，进程间通信无非几种：pipe（管道）、消息队列、信号量、Domain Socket。Nodejs中是通过pipe(管道)实现的，pipe作用于之间有血缘关系的进程，通过fork传递，其本身也是一个进程，将一个进程的输出作为另外一个进程的输入。



### 如何对多个Worker进行请求转发

在Nodejs中使用了RoundRobin负载均衡策略，简称RP,它的实现原理是一种无状态的轮询策略，假定每台服务器的硬件资源、处理性能都是相同的，根据进程的数量，依次分配，直到所有进程处理完了，再开始重新计算分配。优点是实现起来简洁也易用，缺点是如果出现某个请求占用的时间较长，就会导致负载不会太均衡。

RP这种负载均衡技术适用于同一组服务器拥有相同的软硬件配置且平均的服务请求响应

RP是一种常见的复杂均衡技术，Nginx中也有使用，另外在RP的基础上还衍生了一个Weighted Round-Robin权重负载均衡轮询算法，简称WRR,同样也是使用轮询的技术，但是在基础上考虑了服务器的处理能力，实现时为服务器加上权重，这种负载均衡算法能够确保高性能的服务器得到更多的使用率，避免低性能的服务器负载过重。

### Nodejs负载均衡策略设置

- RoundRobin,RR。设置时要使用cluster.SCHED_RR,如果通过环境变量设置要使用rr,如果用cluster对象获取 schedulingPolicy数字表示为2
- Shared Socket，SS,设置时要用cluster.SCHED_NONE，如果通过环境变量设置要用node,如果用cluster对象获取schedulingPolicy数字表示为1

```javascript
// cluster对象的schedulingPolicy属性设置
const cluster = require('cluster');

// 策略一：一种轮询的策略，默认值
cluster.schedulingPolicy = cluster.SHCED_RR;

// 策略二:由操作系统调度的策略
cluster.schedulingPolicy = cluster.SCHED_NONE;

cluster.fork();

// 或者通过环境变量 NODE_CLUSTER_SCHED_POLICY设置：
env NODE_CLUSTER_SCHED_POLICY = 'none' node app.js 
```

## 基于Stream实现多文件合并

### 一个简单的Stream操作

创建一个可读流readable一个可写流writeable，通过管道pipe将可写流绑到可读流，一个简单的Stream操作就可以完成

```javascript
const fs = require('fs');
const readable = fs.createReadStream('./log/read.txt');
const writeable = fs.createWriteStream('./log/write.txt');

readable.pipe(writeable)

// readable.pip(destionation[,option])
// destionation：是一个可写流对象，也就是一个数据写入的目标对象
// options:end,读取结束时终止写入流，默认值是true

// 默认情况下不需要手动调用写入流的end方法关闭的，更改end为false写入的目标将会处于一直打开状态，此时就需要监听可读流的end时间，结束之后手动调用可写流的end事件。

readable.pipe(writeable,{
    end:false
});

readable.on('end',()=>{
    writeable.end('结束')
})
```

如果可读流期间发什么什么错误，则写入的目标流将不会关闭，所以需要监听错误事件，手动关闭可写流，防止内存泄露。

### 多个文件通过Stream合并成一个文件

设置可读流的end为false可以保持写入流一直处于打开状态，通过这种方式，一开始可写流处于打开状态，知道所有的可读流结束，我们再将可写流关闭。

```javascript
const fs = require('fs');
const path = require('path');

/**
 * Stream 合并
 * @param {String} sourceFiles 源文件目录名
 * @param {String} targetFile 目标文件
*/

function streamMerge(sourceFiles, targetFile) {
  const scripts = fs.readdirSync(path.resolve(__dirname, sourceFiles)); // 获取源文件目录下的所有文件
  const fileWriteStream = fs.createWriteStream(path.resolve(__dirname, targetFile)); // 创建一个可写流
  streamMergeRecursive(scripts, fileWriteStream);
}


/**
 * Stream 合并的递归调用
 * @param {Array} scripts
 * @param {Stream} fileWriteStream
*/

function streamMergeRecursive(scripts = [], fileWriteStream) {
  // 递归到尾 的情况判断
  if (!scripts.length) {
    return fileWriteStream.end("console.log('Stream 合并完成')") // 最后关闭可写流，防止内存泄露
  }
  const currentFile = path.resolve(__dirname, 'scripts/', scripts.shift());
  const currentReadStream = fs.createReadStream(currentFile); // 获取当前的可读流

  currentReadStream.pipe(fileWriteStream, { end: false });
  currentReadStream.on('end', () => {
    streamMergeRecursive(scripts, fileWriteStream)
  })

  currentReadStream.on('error', (error) => { // 监听错误事件，关闭可读流，防止内存泄露
    console.log(error);
    fileWriteStream.close()
  })
}

streamMerge('./scripts', './script.js')
```

## Stream pipe的使用与实现原理

通过流我们可以将一大块数据拆分称为一小部分一点一点的流动起来，不需要一次性全部读入，在Linux下可以通过`|`符号实现，类似的在Nodejs的Stream模块中同样也为我们提供了 pipe方法来实现

### 未使用Stream pipe的情况

在Nodejs中I/O操作都是异步的，先用util模块的promiseify方法将fs.readFile的callback形式转换为Promise形式

，它将数据一次性读入内存然后再进行返回，当数据文件很大的时候也是对内存的一种消耗，不推荐

```javascript
// koa 的例子
const Koa = require('koa');
const fs = require('fs');
const app = new Koa();
const {promisify} = require('util');
const {resolve} = require('path');
const readFile = promisify(fs.readFile);

app.use(async ctx=>{
    try{
        ctx.body = await readFile(resolve(__dirname,'test.json')))
    }catch(err){
        ctx.body = err
    }
}).listen(3000)
```

### 使用Steam pipe

```javascript
app.use(async ctx=>{
    try{
        const readable = fs.createReadStream(resolve(__dirname,'test.json'));
        ctx.body = readable;       
    }catch(err){
        ctx.body = err;
    }
})
// 在Koa中直接创建一个可读流赋值给ctx.body，框架内封装好了pipe方法，下面为源码
function respond(ctx){
    let body = ctx.body;
    if(body instanceof Stream) return body.pipe(res)
}
```

### 使用与不使用Stream

使用了可读流，通过pipe接口监听data与end事件，把data的可读流拆分称为一小块一小块的数据（chunks），像流水一样源源不断吐给客户端，而不再需要等待整个文件都加载到内存后才发送数据。pipe可以视为流的管道/通道方法，任何类型的流都会有这个方法来处理流的输入与输出。

总体来说，使用流可以大大提升响应时间，又能有效减轻服务器内存的压力

### 源码分析

在应用层调用 fs.createReadStream 方法，找到这个方法创建的可读流对象pipe的方法实现

#### /lib/fs.js

```javascript
// 导出一个createReadStream方法，在这个方法里面创建一个ReadSream可读流对象，且ReadStream来自internal/fs/streams

// 懒加载，主要在用到的时候用来实例化 ReadStream/WriteStream等对象
function lazyLoadStreams(){
    if(!ReadStream){
        ({ReadStream,WriteStream}) = require('internal/fs/streams');
        [FileReadStream,FileWriteStream] = [ReadStream,WriteStream];
    }
}

function createReadStream(path,options){
   lazyLoadStreams();
    return new ReadStream(path,options); // 创建一个可读流
}

module.exports = fs = {
    createReadStream, // 导出 createReadStream 方法
}
```

#### /lib/internal/fs/streams.js

```javascript
// 这个方法定义了构造函数 ReadStream，且在原型上定义了 open、_read、_destroy等方法，没有pipe方法，通过ObjectSetPrototypeOf方法实现了继承，ReadStream继承了Readable在原型中定义的函数，继续查找Readable的实现

const {Readable,Writeable} = require('stream');


function ReadStream(path,options){
    if(!(this instanceof ReadStream)) return new ReadStream(path,options)
    
    Readable.call(this,options)
}

ObjectSetPrototypeOf(ReadStream.prototype,Readable.prototype);
ObjectStreamProtptypeOf(ReadStream,Readable);

ReadStream.prototype.open = function(){}
ReadStream.prototype._read = function(n){}
ReadStream.prototype._destroy = function(err,cb)

module.exports = {
    ReadStream,
    WriteStream
}
```

#### /lib/stream.js

```javascript
// to avoid cross-reference(require) issue

const Stream = module.exports = require('internal/streams/legacy');

Stream.Readable = require('_stream_readable');
Stream.Writable = require('_stream_writable')
Stream.Duplex = require('_stream_duplex');
Stream.Transform = requier('_stream_transform');
Stream.PassThrough = require('_stream_passthrough');
```

#### /lib/internal/streams/legacy.js

```javascript
// 继承了Events 模块，然后在原型上定义了pipe方法，而_stream_readable继承了Stream之后又自己实现了pipe方法
const {ObjectSetPrototypeOf} = primordials;
const EE = require('events');

function Stream(opts){
   	EE.call(this,opts)
}

ObjectSetPrototypeOf(Stream.prototype,EE.prototype);
ObjectSetPrototypeOf(Stream,EE);

Stream.prototype.pipe = function(dest,options){
    // ...
}
module.exports = Stream;
```

#### /lib/\_stream\_readable.js

```javascript
// 定义了Readable构造函数，且继承于lib/stream.js的Stream，然后重写pipe方法
module.exports = Readable;
Readable.ReadableState = ReadableState;

const EE = require('events');
const Stream = require('stream');

ObjectSetPrototypeOf(Readable.prototype,Stream.prototype)
ObjectSetPrototypeOf(Readable,Stream);

function Readable(options){
    if(!(this instanceof Readable)) return new Readable(options)
    
    Stream.call(this,options); // 继承自 Stream构造函数的定义
}
```

##### \_stream\_readable.js实现分析

1.声明构造函数Readable，继承Stream的构造函数和原型。

文件继承了events事件，拥有了events在原型中定义的属性，例如on、emit

2.声明pipe方法，订阅data事件

在Stream原型上声明pipe方法，订阅data事件，src为可读对象，dest为可写流对象。在使用pipe方法的时候也是监听的data事件，一边读取一边写入数据。

ondata方法的几个核心的实现：

- dest.write(chunk):接受chunk写入数据，如果内部的缓冲小于创建流时配置的highWaterMark，则返回true（缓存未满）,否则返回false时应该停止向流写入数据，直到‘drain'（清空缓存）事件被触发
- src.pause()：可读流会停止data事件，意味着此时暂停数据写入了

调用src.pause是为了防止读入数据过快来不及写入，如果缓存未满即dest.write(chunk)，这个缓存是根据创建流时创建的highWaterMark属性，默认为16384（16k），对象模式的流默认为16

```javascript
Readable.prototype.pipe = function(dest,options){
    const src = this;
    src.on('data',ondata);
    function ondata(){
        const ret = dest.write(chunk);
        if(ret === false){
            ...
            src.pause();
        }
    }
}
```

3.订阅drain事件，继续流动数据。继续写入事件到流时会触发drain事件，也就是dest.write(chunk)等于false(缓存满了)时，如果ondrain不存在则注册drain事件

```javascript
Readable.prototype.pipe = function(dest,options){
    const src = this;
    src.on('data',ondata);
    function ondata(){
        const ret = dest.write(chunk);
        if(ret === false){
            ...
            if(!ondrain){
        		// When the dest drains, it reduces the awaitDrain counter
        		// on the source.  This would be more elegant with a .once()
        		// handler in flow(), but adding and removing repeatedly is
        		// too slow.    
                ondrain = pipeOnDrain(src);
                dest.on('drain',ondrain);
            }
            src.pause();
        }
    }
    // 当写入流dest耗尽时，它将会在可读流对象 source上减少 awaitDrain计数器，为了确保所有需要缓存的写入都完成，即state.awaitDrain === 0和src可读流上的data事件存在，切换流到流动模式
    function pipeOnDrain(src){
        return function pipeDrainFunctionResult(){
            const state = src._readableState;
            debug('pipeOnDrain',state.awaitDrain);
            if(state.awaitDrain){
                state.awaitDrain--;
            }
            if(state.awaitDrain ===0 && EE.listenerCount(src,'data')){
                state.flowing = true;
                flow(src)
            }
        }
    }
    
    // Stream.read() 从内部缓存拉取并返回数据，如果没有可读的数据，则返回null，在可读流上src还有一个readable属性，如果可以安全地调用readable,read(),则为true
    function slow(stream){
        const state = stream._readableState;
        debug('flow',state.flowing);
        while(state.flowing && stream.read() !== null)
    }
}
```

4.触发data事件。调用readable的resume方法，触发可读流的data事件，进入流动模式

```javascript
Readable.prototype.pipe = function(dest,options){
    const src = this;
    // start the flow if it hasnot been started already.
    if(!state.flowing){
        debug('pipe resume')
        src.resume();
    }
}
```

resume方法内部又调用resume\_()，最终执行了stream.read(0)读取了一次空数据（size设置为0），将会触发实例上的\_read()方法，再触发data事件。

```javascript
function resume(stream,state){
    process.nextTick(resume_,stream,state)
}

function resume_(stream,state){
    debug('resume',state.reading);
    if(!state.reading){
        stream.read(0);
    }
}
```

5.订阅end事件

end事件：当可读流中没有数据可供消费时触发，调用onend函数，执行dest.end()方法，表明已没有数据要被写入可写流，进行关闭（关闭可写流的id）,之后再调用stream.write会导致错误。

```javascript
Readable.prototype.pipe = function(dest,options){
    const doEnd = (!pipeOpts || pipeOpts.end !== false) && dest !== process.stdout &&
          dest !== process.stderr;
    const endFn = doEnd?onend:unpipe;
    if(state.endEmitted){
        process.nestTick(endFn)
    }else{
        src.once('end',endFn)
    }
    dest.on('unpipe',onunpipe)
    
    function onend(){
        debug('onend');
        dest.end();
    }
}
```

6.触发pipe事件，传入可读流对象

```javascript
Readable.prototype.pipe = function(dest,options){
    const source = this;
    dest.emit('pipe',src);
}
```

在应用层使用但的时候可以在可写流上订阅pipe事件，做一些判断。

7.支持链式调用，最后返回dest

```javascript
Stream.protptype.pipe = function(dest,options){
    return dest;
}
```







